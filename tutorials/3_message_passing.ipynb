{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb2ff9f",
   "metadata": {},
   "source": [
    "# 写你自己的 GNN 模块\n",
    "\n",
    "通常，模型并不是仅仅通过简单堆叠现有 GNN 模块实现的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4081fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d48231",
   "metadata": {},
   "source": [
    "# 信息传递\n",
    "\n",
    "尽管可以使用 DGL 内建函数 `dgl.nn.SAGEConv` 实现 GraphSAGE，本教程中也可以自行搭建  \n",
    "\n",
    "关于下面代码中 `g.update_all` 用法，其收集并平均相邻特征：\n",
    " - message 函数 `fn.copy_u('h', 'm')` 复制名为 `h` 的节点特征作为名为 `m` 的 *message* 并发送给相邻节点；\n",
    " - reduce 函数 `fn.mean('m', 'h_N')` 将所有收到的名为 `m` 的 messages 平均，后保存为一个新的名为 `h_N` 的节点特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377cc53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConv(nn.Module):\n",
    "    '''Graph convolution module used by the GraphSAGE model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat: int\n",
    "        Input feature size\n",
    "    out_feat: int\n",
    "        Output feature size\n",
    "    '''\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(SAGEConv, self).__init__()\n",
    "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
    "    \n",
    "    def forward(self, g, h):\n",
    "        '''Forward computation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        g: Graph\n",
    "            The input graph.\n",
    "        h: Tensor\n",
    "            The input node feature\n",
    "        '''\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.update_all(\n",
    "                message_func = fn.copy_u('h', 'm'),\n",
    "                reduce_func = fn.mean('m', 'h_N'),\n",
    "            )\n",
    "            h_N = g.ndata['h_N']\n",
    "            h_total = torch.cat([h, h_N], dim=1)\n",
    "            return self.linear(h_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f7cf0",
   "metadata": {},
   "source": [
    "可以堆叠自己的 GraphSAGE 卷积层，从而形成多层的 GraphSAGE 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70baeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats)\n",
    "        self.conv2 = SAGEConv(h_feats, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bd581",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c7288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=10556,\n",
       "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7475a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    all_logits = []\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    \n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    \n",
    "    for e in range(200):\n",
    "        # forward\n",
    "        logits = model(g, features)\n",
    "        \n",
    "        # compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "        \n",
    "        # compute accuracy\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "        \n",
    "        # update best accuracy\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_logits.append(logits.detach())\n",
    "        \n",
    "        if e % 5 == 0:\n",
    "            print('In epoch {}, loss {:.3f}, val acc {:.3f} (best {:.3f}), test acc {:.3f} (best {:.3f})'\\\n",
    "                 .format(e, loss, val_acc, best_val_acc, test_acc, best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d55ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss 1.952, val acc 0.122 (best 0.122), test acc 0.130 (best 0.130)\n",
      "In epoch 5, loss 1.881, val acc 0.236 (best 0.236), test acc 0.243 (best 0.243)\n",
      "In epoch 10, loss 1.742, val acc 0.356 (best 0.424), test acc 0.352 (best 0.409)\n",
      "In epoch 15, loss 1.534, val acc 0.436 (best 0.436), test acc 0.431 (best 0.431)\n",
      "In epoch 20, loss 1.269, val acc 0.558 (best 0.558), test acc 0.540 (best 0.540)\n",
      "In epoch 25, loss 0.974, val acc 0.634 (best 0.634), test acc 0.623 (best 0.623)\n",
      "In epoch 30, loss 0.691, val acc 0.674 (best 0.674), test acc 0.678 (best 0.678)\n",
      "In epoch 35, loss 0.453, val acc 0.710 (best 0.710), test acc 0.711 (best 0.711)\n",
      "In epoch 40, loss 0.280, val acc 0.740 (best 0.740), test acc 0.753 (best 0.753)\n",
      "In epoch 45, loss 0.168, val acc 0.738 (best 0.744), test acc 0.749 (best 0.754)\n",
      "In epoch 50, loss 0.102, val acc 0.748 (best 0.752), test acc 0.752 (best 0.751)\n",
      "In epoch 55, loss 0.064, val acc 0.746 (best 0.752), test acc 0.760 (best 0.751)\n",
      "In epoch 60, loss 0.043, val acc 0.748 (best 0.752), test acc 0.764 (best 0.751)\n",
      "In epoch 65, loss 0.031, val acc 0.746 (best 0.752), test acc 0.763 (best 0.751)\n",
      "In epoch 70, loss 0.023, val acc 0.746 (best 0.752), test acc 0.764 (best 0.751)\n",
      "In epoch 75, loss 0.018, val acc 0.748 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 80, loss 0.015, val acc 0.748 (best 0.752), test acc 0.761 (best 0.751)\n",
      "In epoch 85, loss 0.013, val acc 0.750 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 90, loss 0.011, val acc 0.750 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 95, loss 0.010, val acc 0.750 (best 0.752), test acc 0.761 (best 0.751)\n",
      "In epoch 100, loss 0.009, val acc 0.750 (best 0.752), test acc 0.761 (best 0.751)\n",
      "In epoch 105, loss 0.008, val acc 0.750 (best 0.752), test acc 0.761 (best 0.751)\n",
      "In epoch 110, loss 0.008, val acc 0.750 (best 0.752), test acc 0.761 (best 0.751)\n",
      "In epoch 115, loss 0.007, val acc 0.750 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 120, loss 0.007, val acc 0.750 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 125, loss 0.006, val acc 0.750 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 130, loss 0.006, val acc 0.750 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 135, loss 0.005, val acc 0.750 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 140, loss 0.005, val acc 0.748 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 145, loss 0.005, val acc 0.748 (best 0.752), test acc 0.762 (best 0.751)\n",
      "In epoch 150, loss 0.005, val acc 0.748 (best 0.752), test acc 0.763 (best 0.751)\n",
      "In epoch 155, loss 0.004, val acc 0.750 (best 0.752), test acc 0.763 (best 0.751)\n",
      "In epoch 160, loss 0.004, val acc 0.752 (best 0.752), test acc 0.763 (best 0.751)\n",
      "In epoch 165, loss 0.004, val acc 0.752 (best 0.752), test acc 0.763 (best 0.751)\n",
      "In epoch 170, loss 0.004, val acc 0.752 (best 0.752), test acc 0.763 (best 0.751)\n",
      "In epoch 175, loss 0.004, val acc 0.752 (best 0.752), test acc 0.763 (best 0.751)\n",
      "In epoch 180, loss 0.003, val acc 0.752 (best 0.752), test acc 0.763 (best 0.751)\n",
      "In epoch 185, loss 0.003, val acc 0.752 (best 0.752), test acc 0.764 (best 0.751)\n",
      "In epoch 190, loss 0.003, val acc 0.752 (best 0.752), test acc 0.764 (best 0.751)\n",
      "In epoch 195, loss 0.003, val acc 0.752 (best 0.752), test acc 0.763 (best 0.751)\n"
     ]
    }
   ],
   "source": [
    "model = Model(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e56473",
   "metadata": {},
   "source": [
    "## 笔记\n",
    "\n",
    " - model 是通过 Model 定义的，三个输入参数为输入、隐含、输出的特征数量\n",
    " - train 函数中，logits 值为当前模型的输出值，是由 model(g, features) 获得的（其实这两个参数 g 和 features 均为常量，logits 在每轮训练中不同的原因是调整了 model 中各神经元的权重）\n",
    " - logits 的 shape 为（节点数 x 类别数），即每个节点都有 7 个相应的计算值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112af18a",
   "metadata": {},
   "source": [
    "# 更多的自定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f6522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSAGEConv(nn.Module):\n",
    "    '''Graph convolution module used by the GraphSAGE model with edge weights.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat: int\n",
    "        Input feature size\n",
    "    out_feat: int\n",
    "        Output feature size\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(WeightedSAGEConv, self).__init__()\n",
    "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
    "        \n",
    "    def forward(self, g, h, w):\n",
    "        '''Forward computation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        g: Graph\n",
    "            The input graph.\n",
    "        h: Tensor\n",
    "            The input node feature.\n",
    "        w: Tensor\n",
    "            The edge weight.\n",
    "        '''\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.edata['w'] = w\n",
    "            g.update_all(\n",
    "                message_func = fn.u_mul_e('h', 'w', 'm'),\n",
    "                reduce_func = fn.mean('m', 'h_N'),\n",
    "            )\n",
    "            h_N = g.ndata['h_N']\n",
    "            h_total = torch.cat([h, h_N], dim=1)\n",
    "            return self.linear(h_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa963d59",
   "metadata": {},
   "source": [
    "由于数据集中的图并没有边的权重，我们手动分配所有边权重为 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06b0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = WeightedSAGEConv(in_feats, h_feats)\n",
    "        self.conv2 = WeightedSAGEConv(h_feats, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat, torch.ones(g.num_edges(), 1))\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h, torch.ones(g.num_edges(), 1))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89530939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss 1.954, val acc 0.114 (best 0.114), test acc 0.103 (best 0.103)\n",
      "In epoch 5, loss 1.870, val acc 0.232 (best 0.232), test acc 0.236 (best 0.236)\n",
      "In epoch 10, loss 1.718, val acc 0.514 (best 0.588), test acc 0.536 (best 0.577)\n",
      "In epoch 15, loss 1.493, val acc 0.522 (best 0.588), test acc 0.518 (best 0.577)\n",
      "In epoch 20, loss 1.201, val acc 0.560 (best 0.588), test acc 0.573 (best 0.577)\n",
      "In epoch 25, loss 0.880, val acc 0.618 (best 0.618), test acc 0.627 (best 0.627)\n",
      "In epoch 30, loss 0.584, val acc 0.658 (best 0.658), test acc 0.673 (best 0.673)\n",
      "In epoch 35, loss 0.357, val acc 0.714 (best 0.714), test acc 0.719 (best 0.719)\n",
      "In epoch 40, loss 0.209, val acc 0.736 (best 0.736), test acc 0.739 (best 0.739)\n",
      "In epoch 45, loss 0.122, val acc 0.738 (best 0.738), test acc 0.741 (best 0.741)\n",
      "In epoch 50, loss 0.074, val acc 0.742 (best 0.742), test acc 0.743 (best 0.743)\n",
      "In epoch 55, loss 0.048, val acc 0.740 (best 0.742), test acc 0.746 (best 0.743)\n",
      "In epoch 60, loss 0.033, val acc 0.736 (best 0.742), test acc 0.748 (best 0.743)\n",
      "In epoch 65, loss 0.025, val acc 0.732 (best 0.742), test acc 0.746 (best 0.743)\n",
      "In epoch 70, loss 0.019, val acc 0.736 (best 0.742), test acc 0.746 (best 0.743)\n",
      "In epoch 75, loss 0.016, val acc 0.732 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 80, loss 0.014, val acc 0.732 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 85, loss 0.012, val acc 0.732 (best 0.742), test acc 0.746 (best 0.743)\n",
      "In epoch 90, loss 0.010, val acc 0.732 (best 0.742), test acc 0.745 (best 0.743)\n",
      "In epoch 95, loss 0.009, val acc 0.732 (best 0.742), test acc 0.745 (best 0.743)\n",
      "In epoch 100, loss 0.009, val acc 0.732 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 105, loss 0.008, val acc 0.732 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 110, loss 0.007, val acc 0.734 (best 0.742), test acc 0.748 (best 0.743)\n",
      "In epoch 115, loss 0.007, val acc 0.734 (best 0.742), test acc 0.748 (best 0.743)\n",
      "In epoch 120, loss 0.006, val acc 0.732 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 125, loss 0.006, val acc 0.734 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 130, loss 0.006, val acc 0.734 (best 0.742), test acc 0.749 (best 0.743)\n",
      "In epoch 135, loss 0.005, val acc 0.734 (best 0.742), test acc 0.749 (best 0.743)\n",
      "In epoch 140, loss 0.005, val acc 0.734 (best 0.742), test acc 0.750 (best 0.743)\n",
      "In epoch 145, loss 0.005, val acc 0.734 (best 0.742), test acc 0.750 (best 0.743)\n",
      "In epoch 150, loss 0.004, val acc 0.734 (best 0.742), test acc 0.749 (best 0.743)\n",
      "In epoch 155, loss 0.004, val acc 0.734 (best 0.742), test acc 0.749 (best 0.743)\n",
      "In epoch 160, loss 0.004, val acc 0.734 (best 0.742), test acc 0.749 (best 0.743)\n",
      "In epoch 165, loss 0.004, val acc 0.734 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 170, loss 0.004, val acc 0.734 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 175, loss 0.003, val acc 0.734 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 180, loss 0.003, val acc 0.734 (best 0.742), test acc 0.747 (best 0.743)\n",
      "In epoch 185, loss 0.003, val acc 0.734 (best 0.742), test acc 0.746 (best 0.743)\n",
      "In epoch 190, loss 0.003, val acc 0.734 (best 0.742), test acc 0.746 (best 0.743)\n",
      "In epoch 195, loss 0.003, val acc 0.734 (best 0.742), test acc 0.746 (best 0.743)\n"
     ]
    }
   ],
   "source": [
    "model = Model(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91658a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
