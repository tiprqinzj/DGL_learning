{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da513c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'\n",
    "\n",
    "import dgl\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a99718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "    \n",
    "    def forward(self, g, h):\n",
    "        h = F.relu(self.conv1(g, h))\n",
    "        h = F.relu(self.conv2(g, h))\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            hg = dgl.mean_nodes(g, 'h')\n",
    "            logits = self.classify(hg)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb265e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.GINDataset('MUTAG', False)\n",
    "\n",
    "dataloader = GraphDataLoader(dataset, batch_size=1024, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c025b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = list(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc27f77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GraphConv(in=7, out=20, normalization=both, activation=None)\n",
       "  (conv2): GraphConv(in=20, out=20, normalization=both, activation=None)\n",
       "  (classify): Linear(in_features=20, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(7, 20, 5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e845f12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[ 0.4071, -0.3284,  0.1131, -0.1439,  0.1569,  0.4531, -0.2887,  0.4667,\n",
       "                        0.2787,  0.2067, -0.3740, -0.0412,  0.1453, -0.2694,  0.0724, -0.3103,\n",
       "                        0.2829,  0.1558, -0.4469,  0.2382],\n",
       "                      [ 0.2141, -0.4440,  0.1798, -0.2074,  0.2522,  0.1700,  0.3815,  0.1576,\n",
       "                        0.3682, -0.0556, -0.3880, -0.3067, -0.0109,  0.3489, -0.1416,  0.2301,\n",
       "                        0.1008, -0.0502,  0.1041,  0.3265],\n",
       "                      [-0.2747,  0.2322, -0.1554, -0.2519, -0.0464, -0.0629, -0.2695, -0.1921,\n",
       "                        0.3574, -0.2102,  0.1038,  0.2773,  0.3896, -0.3642, -0.1041,  0.2278,\n",
       "                       -0.0249, -0.1925, -0.4129, -0.0535],\n",
       "                      [ 0.3161, -0.1561,  0.4137,  0.4025, -0.3294,  0.0369,  0.0079, -0.3210,\n",
       "                        0.2718,  0.1824,  0.4682, -0.2233,  0.1201, -0.4672, -0.2559, -0.0445,\n",
       "                       -0.2120, -0.4221,  0.0561,  0.2982],\n",
       "                      [ 0.0355,  0.2598,  0.0485,  0.3244,  0.4371, -0.0722,  0.2683, -0.1300,\n",
       "                       -0.3728,  0.2723, -0.2839, -0.0880, -0.4430, -0.2018,  0.4567, -0.3069,\n",
       "                        0.2885, -0.4217, -0.2367,  0.3619],\n",
       "                      [ 0.0628, -0.0541,  0.0729,  0.1112,  0.2917,  0.2011, -0.0178,  0.1748,\n",
       "                       -0.3538,  0.0793, -0.4363,  0.3882,  0.4155,  0.4344, -0.3283, -0.0562,\n",
       "                       -0.4448,  0.1142, -0.1273,  0.0686],\n",
       "                      [ 0.2011,  0.2206,  0.3271, -0.1332, -0.1299, -0.1510,  0.0732, -0.1886,\n",
       "                       -0.3847,  0.3324,  0.1066,  0.2870,  0.3176, -0.2087,  0.3185,  0.0852,\n",
       "                       -0.3327,  0.0014,  0.1012,  0.3641]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[ 0.2970, -0.0125, -0.2232, -0.0980, -0.0572,  0.1522, -0.1735, -0.0247,\n",
       "                        0.2974, -0.0026, -0.3532, -0.2331, -0.0575, -0.3762, -0.1894,  0.2333,\n",
       "                        0.0200,  0.0771,  0.0546,  0.0527],\n",
       "                      [ 0.0498,  0.2795,  0.2322,  0.2866,  0.0726,  0.3325,  0.0639,  0.1725,\n",
       "                       -0.1330,  0.1765,  0.1507, -0.0743,  0.2255, -0.1940, -0.1957, -0.0384,\n",
       "                       -0.0755,  0.3520, -0.3231,  0.3673],\n",
       "                      [-0.2248,  0.3346, -0.2194, -0.3349, -0.0453,  0.2640, -0.3389,  0.0588,\n",
       "                        0.0474,  0.3430,  0.2140,  0.0867,  0.1845,  0.2905, -0.2174, -0.0588,\n",
       "                       -0.3809,  0.2986, -0.1072,  0.2286],\n",
       "                      [ 0.3714,  0.2180, -0.3496, -0.1439,  0.0386,  0.2765,  0.3421, -0.1019,\n",
       "                        0.3058, -0.0041,  0.3192, -0.1779, -0.2420, -0.1572,  0.3040,  0.1308,\n",
       "                        0.1230,  0.1989, -0.2378,  0.1863],\n",
       "                      [ 0.1130,  0.3256,  0.0801, -0.1156,  0.3253,  0.2262,  0.2964,  0.1353,\n",
       "                        0.0453, -0.2977,  0.1287, -0.2207,  0.3676, -0.1720, -0.1781,  0.3310,\n",
       "                       -0.0129,  0.2860, -0.0188, -0.1422],\n",
       "                      [ 0.2554,  0.3808,  0.2952, -0.2178, -0.2356, -0.0718,  0.2356,  0.0285,\n",
       "                        0.2814,  0.2001,  0.3537,  0.3241, -0.1878, -0.2932,  0.0591,  0.3712,\n",
       "                       -0.0331, -0.1855, -0.3230,  0.2728],\n",
       "                      [-0.2628,  0.2590, -0.3372, -0.2953,  0.3809,  0.2257, -0.1562,  0.0615,\n",
       "                       -0.1706,  0.0164,  0.2701, -0.3259,  0.2424, -0.0806, -0.1355, -0.1354,\n",
       "                        0.1488,  0.2513,  0.2224,  0.0872],\n",
       "                      [-0.2050,  0.1633,  0.2438,  0.0827, -0.2788,  0.2473,  0.3778, -0.3504,\n",
       "                        0.3075,  0.0723, -0.1231, -0.1656, -0.2553, -0.3500, -0.1977,  0.0687,\n",
       "                       -0.2714,  0.1711,  0.1635,  0.2458],\n",
       "                      [ 0.3403, -0.2634,  0.3354,  0.1841,  0.0401,  0.1629,  0.2429,  0.3250,\n",
       "                       -0.2163,  0.2288,  0.3103,  0.3807, -0.0625, -0.0555, -0.2938, -0.3626,\n",
       "                        0.0062,  0.2233, -0.2150, -0.1222],\n",
       "                      [ 0.2086, -0.1787, -0.0053,  0.1081, -0.3123, -0.0056,  0.2296, -0.2129,\n",
       "                        0.3689, -0.0733,  0.0987, -0.2665,  0.3150,  0.0388,  0.0327, -0.0943,\n",
       "                       -0.3116, -0.3354,  0.0459, -0.3617],\n",
       "                      [ 0.2133, -0.3528, -0.0590,  0.2512,  0.0302,  0.2512, -0.1922,  0.3598,\n",
       "                        0.2904, -0.1352, -0.2953, -0.3675,  0.2624,  0.3136, -0.1216, -0.0720,\n",
       "                       -0.3849,  0.0296, -0.2353,  0.3529],\n",
       "                      [-0.2345,  0.2046, -0.2848, -0.3520,  0.0520,  0.2009,  0.3780, -0.3615,\n",
       "                        0.1773,  0.1436, -0.1214,  0.0488,  0.2314, -0.1878, -0.1998,  0.2199,\n",
       "                        0.2591, -0.2086, -0.1916, -0.3749],\n",
       "                      [ 0.0944,  0.0381,  0.3794, -0.1686,  0.1573, -0.1352, -0.1946,  0.3309,\n",
       "                        0.3728, -0.3011, -0.2891, -0.0066,  0.2582, -0.1964,  0.2639, -0.3411,\n",
       "                        0.1780, -0.1739, -0.1837,  0.0161],\n",
       "                      [ 0.2290, -0.1889, -0.3417, -0.2192,  0.3295, -0.0081,  0.3487,  0.0409,\n",
       "                        0.3042, -0.3503, -0.3226, -0.2649,  0.1992,  0.0006,  0.3065, -0.1880,\n",
       "                       -0.0849, -0.0560,  0.0111, -0.1846],\n",
       "                      [-0.1786,  0.0326, -0.0168,  0.0169,  0.2028,  0.2679,  0.1813, -0.2656,\n",
       "                       -0.2170, -0.1501,  0.0825,  0.2835, -0.1400, -0.2415, -0.0989, -0.1083,\n",
       "                       -0.1332,  0.0850, -0.0121, -0.3677],\n",
       "                      [-0.2615, -0.1688, -0.2451,  0.2571, -0.2665,  0.2098, -0.3270,  0.1037,\n",
       "                        0.0707, -0.1368, -0.0973,  0.0603,  0.3771, -0.2907,  0.1520,  0.2780,\n",
       "                       -0.1558, -0.3388,  0.2502,  0.2278],\n",
       "                      [ 0.1109,  0.3870,  0.2277, -0.0843, -0.2735,  0.1952,  0.1852, -0.3773,\n",
       "                        0.2422,  0.1204, -0.1783, -0.0936, -0.3654,  0.3561, -0.2532, -0.0412,\n",
       "                        0.2888, -0.2873, -0.2420, -0.3302],\n",
       "                      [-0.2520, -0.1104, -0.2459, -0.3348, -0.2431,  0.3101,  0.1232, -0.0336,\n",
       "                       -0.0190, -0.1410,  0.2516, -0.1613,  0.2481, -0.2116, -0.2079,  0.1447,\n",
       "                       -0.0899,  0.3187,  0.2562, -0.1872],\n",
       "                      [-0.0724,  0.0584, -0.0043, -0.2010, -0.0046, -0.2732,  0.0977, -0.2918,\n",
       "                       -0.0799, -0.0398, -0.1712,  0.2778, -0.2685,  0.0318, -0.1113, -0.2204,\n",
       "                        0.0514, -0.0362, -0.2890,  0.1239],\n",
       "                      [-0.2405,  0.0346, -0.3128, -0.1941,  0.2084,  0.2432, -0.0636, -0.2565,\n",
       "                       -0.2429, -0.0633,  0.1967,  0.1226, -0.0506, -0.2968, -0.0991, -0.3749,\n",
       "                       -0.3075,  0.3742,  0.0059,  0.2835]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('classify.weight',\n",
       "              tensor([[-0.1397,  0.0990,  0.0959,  0.0533, -0.0697,  0.1736,  0.1752, -0.0975,\n",
       "                       -0.0103,  0.1858,  0.0605,  0.0884, -0.1384,  0.2180,  0.1873, -0.1878,\n",
       "                       -0.0972, -0.2001,  0.1954, -0.1017],\n",
       "                      [ 0.1506, -0.2049,  0.0121,  0.0664, -0.1700, -0.2060,  0.1981,  0.2122,\n",
       "                        0.1601, -0.0638,  0.0930,  0.1794,  0.2110,  0.1931, -0.1889, -0.0366,\n",
       "                       -0.1092,  0.1942,  0.0598, -0.1564],\n",
       "                      [ 0.0517, -0.1077, -0.2232, -0.0023, -0.0652, -0.0664, -0.0904, -0.1457,\n",
       "                        0.1453, -0.0184,  0.0767, -0.1090, -0.0482, -0.2110,  0.1690, -0.0275,\n",
       "                        0.0573,  0.1897,  0.0196,  0.1583],\n",
       "                      [-0.1945, -0.2090,  0.1195, -0.0390,  0.0856, -0.1148, -0.0346, -0.1014,\n",
       "                       -0.1475, -0.1339, -0.0223, -0.0362,  0.1499,  0.0130,  0.1306,  0.1658,\n",
       "                        0.2070, -0.0143, -0.0657, -0.2024],\n",
       "                      [ 0.0560, -0.0966,  0.1510, -0.1944, -0.1258,  0.0047,  0.1165,  0.2095,\n",
       "                        0.0604,  0.1563,  0.1751, -0.0340, -0.0683, -0.1906, -0.0314,  0.0414,\n",
       "                        0.1487, -0.1759, -0.0632, -0.0223]])),\n",
       "             ('classify.bias',\n",
       "              tensor([ 0.0850, -0.0075, -0.1095,  0.0778, -0.1091]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6537dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2414e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    for batched_graph, labels in dataloader:\n",
    "        feats = batched_graph.ndata['attr']\n",
    "        logits = model(batched_graph, feats)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8211abf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[ 0.3640, -0.1542,  0.2849, -0.0370,  0.3416,  0.6301, -0.3498,  0.6455,\n",
       "                        0.4624,  0.3857, -0.3740,  0.1338,  0.2111, -0.3417,  0.2497, -0.3103,\n",
       "                        0.4562,  0.2516, -0.4369,  0.3827],\n",
       "                      [ 0.1087, -0.5791,  0.1289, -0.2526,  0.4409,  0.2870,  0.1751,  0.1103,\n",
       "                        0.5113,  0.1463, -0.3880, -0.1992,  0.1954,  0.5575, -0.2779,  0.3645,\n",
       "                        0.0164,  0.0149, -0.0574,  0.1705],\n",
       "                      [-0.3335,  0.3267, -0.0420, -0.2783,  0.0443,  0.0068, -0.3066, -0.2291,\n",
       "                        0.4723, -0.0059, -0.0280,  0.4410,  0.5805, -0.3642,  0.0265,  0.3609,\n",
       "                       -0.0444, -0.1481, -0.4233, -0.1572],\n",
       "                      [ 0.3515, -0.1972,  0.4163,  0.5588, -0.3176,  0.2084, -0.1730, -0.3210,\n",
       "                        0.3433,  0.3848,  0.6382, -0.1717,  0.3230, -0.4672, -0.4420, -0.1459,\n",
       "                       -0.2120, -0.4221, -0.0391,  0.1181],\n",
       "                      [ 0.1773,  0.4546,  0.2436,  0.5022,  0.5824,  0.0030,  0.4376, -0.0749,\n",
       "                       -0.3728,  0.2630, -0.2839,  0.1048, -0.4959, -0.2301,  0.6559, -0.3069,\n",
       "                        0.4090, -0.4217, -0.1125,  0.5179],\n",
       "                      [-0.0071,  0.1099,  0.2270,  0.2875,  0.4778,  0.3818, -0.0876,  0.3456,\n",
       "                       -0.2403,  0.2790, -0.4363,  0.5609,  0.4515,  0.6370, -0.1776, -0.1623,\n",
       "                       -0.3459,  0.2995,  0.0195,  0.1325],\n",
       "                      [ 0.2401,  0.4007,  0.5082,  0.0343,  0.0500,  0.0289,  0.1757, -0.0009,\n",
       "                       -0.1958,  0.5053, -0.0153,  0.4653,  0.2496, -0.0288,  0.5025, -0.0071,\n",
       "                       -0.1778,  0.1265,  0.2542,  0.4957]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([ 0.0205,  0.1782,  0.1779,  0.1861,  0.1862,  0.1872,  0.0951,  0.1922,\n",
       "                       0.1869,  0.1853, -0.1215,  0.1775, -0.0431,  0.1949,  0.1820, -0.0910,\n",
       "                       0.1634,  0.1497,  0.1529,  0.1266])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[ 4.2284e-01,  1.5200e-01, -3.5016e-02, -9.8012e-02, -1.3504e-01,\n",
       "                        3.1716e-01, -7.7920e-03, -1.1392e-01,  4.7891e-01,  1.6029e-01,\n",
       "                       -2.0105e-01, -7.1023e-02, -7.9460e-02, -3.7623e-01, -2.1487e-01,\n",
       "                        1.7974e-01, -3.2768e-02, -1.6122e-02,  2.2507e-01, -1.4206e-02],\n",
       "                      [ 2.0749e-01,  4.6361e-01,  3.5686e-01,  2.8658e-01, -4.5105e-03,\n",
       "                        5.1694e-01,  2.4225e-01,  2.2533e-01,  4.6774e-02,  3.5351e-01,\n",
       "                        3.0276e-01,  1.0290e-01,  2.0554e-01, -1.9404e-01, -1.5881e-01,\n",
       "                       -1.0377e-01, -7.5543e-02,  2.5160e-01, -1.9181e-01,  3.1174e-01],\n",
       "                      [-9.0850e-02,  5.1432e-01, -4.2482e-02, -3.3486e-01, -1.2406e-01,\n",
       "                        4.4349e-01, -1.6061e-01, -3.0979e-02,  2.3248e-01,  5.1729e-01,\n",
       "                        3.6853e-01,  2.6289e-01,  1.9933e-01,  2.9046e-01, -2.3846e-01,\n",
       "                       -1.1308e-01, -4.3364e-01,  2.0226e-01,  5.7987e-02,  1.6531e-01],\n",
       "                      [ 5.0716e-01,  4.0392e-01, -2.2527e-01, -1.4388e-01, -5.4080e-02,\n",
       "                        4.5559e-01,  5.3742e-01, -1.9122e-01,  5.0102e-01,  1.6354e-01,\n",
       "                        4.5313e-01, -1.7132e-02, -1.0279e-01, -1.5721e-01,  2.3741e-01,\n",
       "                        3.2678e-02,  7.0133e-02,  2.0029e-01, -1.1868e-01,  7.7101e-02],\n",
       "                      [ 2.3817e-01,  5.0456e-01,  2.6338e-01, -1.1556e-01,  2.3218e-01,\n",
       "                        3.9840e-01,  4.8770e-01,  1.3527e-01,  2.4113e-01, -1.2258e-01,\n",
       "                        2.8848e-01, -4.5391e-02,  5.1051e-01, -1.7198e-01, -2.4665e-01,\n",
       "                        2.7548e-01, -6.5852e-02,  2.1661e-01,  1.4906e-01, -2.1594e-01],\n",
       "                      [ 3.8386e-01,  5.5616e-01,  4.8244e-01, -2.1777e-01, -3.2824e-01,\n",
       "                        9.7531e-02,  4.2362e-01, -5.5209e-02,  4.7723e-01,  3.7538e-01,\n",
       "                        5.1528e-01,  4.9888e-01, -6.7500e-02, -2.9325e-01, -8.7692e-03,\n",
       "                        3.1734e-01, -8.6075e-02, -2.6741e-01, -1.7418e-01,  2.0100e-01],\n",
       "                      [-1.2569e-01,  4.4193e-01, -1.9346e-01, -2.9526e-01,  3.0768e-01,\n",
       "                        4.1028e-01,  3.0164e-02,  3.6324e-03,  2.0106e-02,  2.0014e-01,\n",
       "                        4.5525e-01, -1.4389e-01,  2.3891e-01, -8.0579e-02, -8.2914e-02,\n",
       "                       -1.7409e-01,  1.4877e-01,  1.7007e-01,  4.0062e-01,  2.8206e-02],\n",
       "                      [-7.6109e-02,  3.3671e-01,  4.3026e-01,  8.2742e-02, -3.7097e-01,\n",
       "                        4.1435e-01,  5.6474e-01, -3.5038e-01,  5.0336e-01,  2.4571e-01,\n",
       "                        3.8494e-02,  8.4201e-03, -1.4364e-01, -3.4997e-01, -2.6495e-01,\n",
       "                        1.4870e-02, -3.2435e-01,  8.8125e-02,  3.0335e-01,  1.7403e-01],\n",
       "                      [ 4.7592e-01, -9.5454e-02,  5.1598e-01,  1.8407e-01, -1.3459e-02,\n",
       "                        3.2283e-01,  4.2896e-01,  2.3624e-01, -1.9641e-02,  3.9565e-01,\n",
       "                        4.7185e-01,  5.5264e-01,  2.6303e-02, -5.5478e-02, -2.9377e-01,\n",
       "                       -4.1564e-01,  6.1747e-03,  1.3395e-01, -8.7719e-02, -1.9420e-01],\n",
       "                      [ 3.3669e-01,  3.9088e-04,  1.7401e-01,  1.0811e-01, -3.9064e-01,\n",
       "                        1.7325e-01,  4.0785e-01, -3.0294e-01,  5.5424e-01,  1.0088e-01,\n",
       "                        2.5298e-01, -9.0641e-02,  3.2518e-01,  3.8847e-02,  1.0523e-02,\n",
       "                       -1.4835e-01, -3.6437e-01, -4.3221e-01,  2.0982e-01, -4.2499e-01],\n",
       "                      [ 4.1766e-01, -2.4774e-01,  1.6255e-02,  2.5124e-01, -3.9482e-02,\n",
       "                        3.5432e-01, -8.0229e-02,  2.7029e-01,  4.3668e-01, -3.6767e-02,\n",
       "                       -1.9331e-01, -2.5706e-01,  1.9471e-01,  3.1358e-01, -1.2156e-01,\n",
       "                       -7.1958e-02, -3.8495e-01, -5.8448e-02, -1.2966e-01,  2.9256e-01],\n",
       "                      [-1.1859e-01,  3.8440e-01, -1.1576e-01, -3.5203e-01, -2.8492e-02,\n",
       "                        3.8028e-01,  5.5669e-01, -3.0862e-01,  3.6293e-01,  3.1717e-01,\n",
       "                        3.1583e-02,  2.2624e-01,  2.5420e-01, -1.8779e-01, -2.6181e-01,\n",
       "                        1.5777e-01,  2.0608e-01, -3.0707e-01, -3.3870e-02, -4.3261e-01],\n",
       "                      [ 2.1889e-01,  1.9773e-01,  5.6006e-01, -1.6862e-01,  7.9321e-02,\n",
       "                        2.4227e-02, -3.1596e-02,  2.7519e-01,  5.5386e-01, -1.4304e-01,\n",
       "                       -1.4038e-01,  1.5606e-01,  2.5004e-01, -1.9638e-01,  2.0155e-01,\n",
       "                       -3.9575e-01,  1.2498e-01, -2.6716e-01, -1.8134e-02, -4.5366e-02],\n",
       "                      [ 3.4035e-01, -2.7193e-02, -2.0918e-01, -2.1917e-01,  2.3702e-01,\n",
       "                        1.3435e-01,  5.3869e-01,  4.0921e-02,  5.0349e-01, -2.1496e-01,\n",
       "                       -1.4339e-01, -9.8364e-02,  3.4741e-01,  6.1101e-04,  2.3777e-01,\n",
       "                       -2.8597e-01, -1.3793e-01, -6.7777e-02,  1.8069e-01, -2.7234e-01],\n",
       "                      [-6.3475e-02,  2.1477e-01,  1.6040e-01,  1.6880e-02,  1.2680e-01,\n",
       "                        4.5049e-01,  3.5919e-01, -2.1288e-01, -3.6875e-02,  2.6210e-02,\n",
       "                        2.3617e-01,  4.5883e-01, -1.7169e-01, -2.4150e-01, -4.5980e-02,\n",
       "                       -1.6182e-01, -1.3322e-01, -1.3905e-02,  1.5096e-01, -4.2795e-01],\n",
       "                      [-9.3407e-02, -4.8412e-02, -1.6043e-01,  2.5713e-01, -3.4568e-01,\n",
       "                        3.2906e-01, -2.0694e-01,  1.5643e-01,  2.1488e-01, -2.5214e-02,\n",
       "                        3.2265e-02,  1.7959e-01,  3.0338e-01, -2.9072e-01,  2.0213e-01,\n",
       "                        2.7040e-01, -1.5576e-01, -4.3396e-01,  4.2796e-01,  1.6896e-01],\n",
       "                      [ 2.4609e-01,  5.5926e-01,  4.0917e-01, -8.4303e-02, -3.2492e-01,\n",
       "                        3.6213e-01,  3.6976e-01, -3.7732e-01,  4.3634e-01,  2.9188e-01,\n",
       "                       -1.8136e-02,  7.6246e-02, -2.7593e-01,  3.5614e-01, -2.5325e-01,\n",
       "                       -9.4192e-02,  2.8880e-01, -3.7467e-01, -1.1522e-01, -4.0250e-01],\n",
       "                      [-1.3467e-01,  7.5639e-02, -5.9813e-02, -3.3476e-01, -3.2771e-01,\n",
       "                        4.9308e-01,  3.1592e-01, -3.3574e-02,  1.7597e-01,  4.3218e-02,\n",
       "                        4.0995e-01,  2.0985e-02,  3.7664e-01, -2.1165e-01, -2.7507e-01,\n",
       "                        9.0769e-02, -1.4280e-01,  2.4121e-01,  3.9470e-01, -2.5680e-01],\n",
       "                      [ 9.0910e-02,  2.4753e-01,  1.3697e-01, -2.0097e-01, -7.7269e-02,\n",
       "                       -8.3782e-02,  2.8107e-01, -3.7713e-01,  1.0082e-01,  1.4244e-01,\n",
       "                        6.2543e-03,  4.5905e-01, -2.7437e-01,  3.1824e-02, -5.8754e-02,\n",
       "                       -1.8669e-01,  5.1395e-02, -1.3181e-01, -1.2053e-01,  6.6053e-02],\n",
       "                      [-1.1471e-01,  2.1314e-01, -1.3195e-01, -1.9406e-01,  1.3243e-01,\n",
       "                        4.2180e-01,  1.1506e-01, -3.4614e-01, -5.6420e-02,  1.1135e-01,\n",
       "                        3.5206e-01,  2.9800e-01, -4.7614e-02, -2.9685e-01, -1.0196e-01,\n",
       "                       -4.2861e-01, -3.6028e-01,  2.8000e-01,  1.7295e-01,  2.2039e-01]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.1276,  0.1711,  0.1814,  0.0000, -0.0790,  0.1708,  0.1728, -0.0885,\n",
       "                       0.1841,  0.1683,  0.1518,  0.1705,  0.0180,  0.0000, -0.0602, -0.0541,\n",
       "                      -0.0530, -0.0938,  0.1664, -0.0657])),\n",
       "             ('classify.weight',\n",
       "              tensor([[-0.0312,  0.2767,  0.2667,  0.0533,  0.0012,  0.3487,  0.3495, -0.0148,\n",
       "                        0.1588,  0.3593,  0.2314,  0.2600,  0.0007,  0.2180,  0.2306, -0.1339,\n",
       "                       -0.1492, -0.1191,  0.2320, -0.0418],\n",
       "                      [ 0.3363, -0.0080,  0.2157,  0.0664, -0.0933, -0.0116,  0.3974,  0.1271,\n",
       "                        0.3581,  0.1265,  0.2811,  0.3639,  0.3801,  0.1931, -0.1247,  0.0291,\n",
       "                       -0.0565,  0.2755,  0.2416, -0.0859],\n",
       "                      [-0.1327, -0.2904, -0.4160, -0.0023, -0.1373, -0.2455, -0.2740, -0.2271,\n",
       "                       -0.0328, -0.1969, -0.1007, -0.2844, -0.1924, -0.2110,  0.1102, -0.0846,\n",
       "                        0.0055,  0.1088, -0.1579,  0.0940],\n",
       "                      [-0.3731, -0.3878, -0.0705, -0.0390,  0.0138, -0.2892, -0.2152, -0.1826,\n",
       "                       -0.3205, -0.3098, -0.1976, -0.2089,  0.0114,  0.0130,  0.0719,  0.1089,\n",
       "                        0.1551, -0.0947, -0.2428, -0.2661],\n",
       "                      [-0.1348, -0.2856, -0.0452, -0.1944, -0.1985, -0.1823, -0.0717,  0.1274,\n",
       "                       -0.1264, -0.0263, -0.0057, -0.2138, -0.2250, -0.1906, -0.0904, -0.0163,\n",
       "                        0.0969, -0.2578, -0.2405, -0.0874]])),\n",
       "             ('classify.bias',\n",
       "              tensor([ 0.2422,  0.1644, -0.2684, -0.0764, -0.2774]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bef6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
