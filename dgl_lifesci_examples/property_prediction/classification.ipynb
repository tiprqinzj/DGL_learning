{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba748f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dgllife.model import load_pretrained\n",
    "from dgllife.utils import EarlyStopping, Meter, SMILESToBigraph\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import collate_molgraphs, load_model, predict\n",
    "from utils import init_featurizer, mkdir_p, split_dataset, get_configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b1e95",
   "metadata": {},
   "source": [
    "源码作者将输入参数存于 args 字典，并使用 init_featurizer 函数对参数进行解析。\n",
    "本例中仅仔细研究 GCN & canonical 方法的模型，其它模型可类比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36690ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import CanonicalAtomFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a382e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'dataset': 'BBBP',\n",
    "    'model': 'GCN',\n",
    "    'featurizer_type': 'canonical',\n",
    "    'pretrain': False,\n",
    "    'split': 'scaffold',\n",
    "    'split_ratio': '0.8,0.1,0.1',\n",
    "    'metric': 'roc_auc_score',\n",
    "    'num_epochs': 1000,\n",
    "    'num_workers': 0,\n",
    "    'print_every': 10,\n",
    "    'result_path': 'classification_results',\n",
    "    'device': torch.device('cpu'),\n",
    "    # add by init_featurizer\n",
    "    'node_featurizer': CanonicalAtomFeaturizer(),\n",
    "    'edge_featurizer': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d59e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir\n",
    "if not os.path.exists(args['result_path']):\n",
    "    os.makedirs(args['result_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b68e47d",
   "metadata": {},
   "source": [
    "SMILES to Graph：对 `SMILESToBigraph` 包装后，成为一个新的函数，主要给出节点和边的编码方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dade3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.data import BBBP\n",
    "\n",
    "smiles_to_g = SMILESToBigraph(add_self_loop=True, node_featurizer=args['node_featurizer'],\n",
    "                              edge_featurizer=args['edge_featurizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61efea60",
   "metadata": {},
   "source": [
    "解析 `SMILESToBigraph`\n",
    "- 将 SMILES 字符串转化为双向 `DGLGraphs` 对象并将其特征化\n",
    "- 原子有 74 个特征（待查看）\n",
    "- **需注意**，源码案例中 `add_self_loop` 设置为 True，如果改为False，则会在训练中出错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e3caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=3, num_edges=4,\n",
      "      ndata_schemes={'atomic': Scheme(shape=(1,), dtype=torch.float32)}\n",
      "      edata_schemes={'type': Scheme(shape=(1,), dtype=torch.float32)})\n",
      "{'atomic': tensor([[6.],\n",
      "        [8.],\n",
      "        [6.]])}\n",
      "{'type': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])}\n"
     ]
    }
   ],
   "source": [
    "# 函数自带案例\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "def featurize_atoms(mol):\n",
    "    feats = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        feats.append(atom.GetAtomicNum())\n",
    "    return {'atomic': torch.tensor(feats).reshape(-1, 1).float()}\n",
    "\n",
    "def featurize_bonds(mol):\n",
    "    feats = []\n",
    "    bond_types = [Chem.rdchem.BondType.SINGLE,\n",
    "                  Chem.rdchem.BondType.DOUBLE,\n",
    "                  Chem.rdchem.BondType.TRIPLE,\n",
    "                  Chem.rdchem.BondType.AROMATIC]\n",
    "    for bond in mol.GetBonds():\n",
    "        btype = bond_types.index(bond.GetBondType())\n",
    "        feats.extend([btype, btype])\n",
    "    return {'type': torch.tensor(feats).reshape(-1, 1).float()}\n",
    "\n",
    "smi_to_g = SMILESToBigraph(\n",
    "    node_featurizer=featurize_atoms,\n",
    "    edge_featurizer=featurize_bonds)\n",
    "\n",
    "g = smi_to_g('CCO')\n",
    "\n",
    "print(g)\n",
    "print(g.ndata)\n",
    "print(g.edata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5a17c",
   "metadata": {},
   "source": [
    "使用本例中的 `smiles_to_g` 函数编码 SMILES 后，结果如下：\n",
    "- 返回 DGLGraph 对象，其包含 3 个节点（对应 3 个原子）和 4 个边（对应两个键，双向）\n",
    "- 节点特征名为 'h'，其大小为 3 行 74 列，即每个原子由 74 个数字编码\n",
    "- 边特征为空"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a3fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=3, num_edges=7,\n",
      "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n",
      "{'h': tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0.]])}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "g = smiles_to_g('CCO')\n",
    "\n",
    "print(g)\n",
    "print(g.ndata)\n",
    "print(g.edata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa326f",
   "metadata": {},
   "source": [
    "每个 dataset 的元素返回一个元组，元组中包含 4 个元素：\n",
    "- SMILES\n",
    "- DGLGraph 对象，包含节点数、边数、节点特征（名为 h 的 74 个特征）、边特征（空）\n",
    "- Labels，dtype 为 float32，shape 为 task 个数\n",
    "- masks，dtype 为 float32，表示在多任务学习中该图是否存在 Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682b6226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dgl graphs from scratch...\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Invalid mol found\n",
      "Processing molecule 1000/2050\n",
      "Processing molecule 2000/2050\n"
     ]
    }
   ],
   "source": [
    "dataset = BBBP(smiles_to_graph=smiles_to_g, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2056b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.n_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "111e1ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[Cl].CC(C)NCC(O)COc1cccc2ccccc12',\n",
       " Graph(num_nodes=20, num_edges=60,\n",
       "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " tensor([1.]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5e53eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2039"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3ba1c",
   "metadata": {},
   "source": [
    "## 划分训练集与测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd649b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.1 0.1\n"
     ]
    }
   ],
   "source": [
    "# utils\n",
    "\n",
    "a,b,c = map(float, '0.8,0.1,0.1'.split(','))\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ad611a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start initializing RDKit molecule instances...\n",
      "Creating RDKit molecule instance 1000/2039\n",
      "Creating RDKit molecule instance 2000/2039\n",
      "Start computing Bemis-Murcko scaffolds.\n",
      "Computing Bemis-Murcko for compound 1000/2039\n",
      "Computing Bemis-Murcko for compound 2000/2039\n"
     ]
    }
   ],
   "source": [
    "from dgllife.utils import ScaffoldSplitter\n",
    "\n",
    "# transfer string to float\n",
    "train_ratio, val_ratio, test_ratio = map(float, args['split_ratio'].split(','))\n",
    "\n",
    "# splitting\n",
    "train_set, val_set, test_set = ScaffoldSplitter.train_val_test_split(\n",
    "    dataset, frac_train=train_ratio, frac_val=val_ratio, frac_test=test_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2593176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dgl.data.utils.Subset at 0x7fa950169f40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8385bec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dgllife.data.bbbp.BBBP at 0x7fa970abebe0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa54fef",
   "metadata": {},
   "source": [
    "## 载入模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "753579e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'batchnorm': False,\n",
       " 'dropout': 0.0272564399565973,\n",
       " 'gnn_hidden_feats': 256,\n",
       " 'lr': 0.02020086171843634,\n",
       " 'num_gnn_layers': 4,\n",
       " 'patience': 30,\n",
       " 'predictor_hidden_feats': 32,\n",
       " 'residual': True,\n",
       " 'weight_decay': 0.001168051063650801}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('configures/BBBP/GCN_canonical.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c4368a",
   "metadata": {},
   "source": [
    "## 训练前的准备工作\n",
    "\n",
    "- `CanonicalAtomFeaturizer() 具有一个 feat_size() 方法，返回它编码的原子特征个数`\n",
    "- 创建一个整理函数 `collate_molgraphs()`，其输入参数为 DGL 数据集，输出我们期待的一系列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5997ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "print(args['node_featurizer'].feat_size())\n",
    "print(CanonicalAtomFeaturizer().feat_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d35ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['in_node_feats'] = args['node_featurizer'].feat_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7662753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "\n",
    "def collate_molgraphs(data):\n",
    "    if len(data[0]) == 3:\n",
    "        smiles, graphs, labels = map(list, zip(*data))\n",
    "    else:\n",
    "        smiles, graphs, labels, masks = map(list, zip(*data))\n",
    "    \n",
    "    bg = dgl.batch(graphs)\n",
    "    bg.set_n_initializer(dgl.init.zero_initializer)\n",
    "    bg.set_e_initializer(dgl.init.zero_initializer)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    \n",
    "    if len(data[0]) == 3:\n",
    "        masks = torch.ones(labels.shape)\n",
    "    else:\n",
    "        masks = torch.stack(masks, dim=0)\n",
    "    \n",
    "    return smiles, bg, labels, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f88b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = collate_molgraphs(train_set)\n",
    "len(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518290b",
   "metadata": {},
   "source": [
    "### 对 collate_molgraphs 拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21dd5d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631\n",
      "tensor([1.])\n",
      "1631\n",
      "Graph(num_nodes=23, num_edges=69,\n",
      "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n",
      "Graph(num_nodes=36682, num_edges=115678,\n",
      "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n",
      "Graph(num_nodes=36682, num_edges=115678,\n",
      "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n",
      "[tensor([1.]), tensor([1.]), tensor([1.]), tensor([1.]), tensor([1.])]\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "smiles, graphs, labels, masks = map(list, zip(*train_set))\n",
    "print(len(smiles))\n",
    "print(labels[0])\n",
    "print(len(graphs))\n",
    "print(graphs[0])\n",
    "\n",
    "bg = dgl.batch(graphs)\n",
    "print(bg)\n",
    "\n",
    "bg.set_n_initializer(dgl.init.zero_initializer)\n",
    "bg.set_e_initializer(dgl.init.zero_initializer)\n",
    "print(bg)\n",
    "\n",
    "print(labels[:5])\n",
    "labels = torch.stack(labels, dim=0)\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfe528ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=config['batch_size'], shuffle=True,\n",
    "                          collate_fn=collate_molgraphs, num_workers=0)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=config['batch_size'], shuffle=True,\n",
    "                        collate_fn=collate_molgraphs, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=config['batch_size'], shuffle=True,\n",
    "                         collate_fn=collate_molgraphs, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28faa08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 4 4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcf9b6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['C1=C(OC)C(=CC2=C1C(=C(C)[NH]2)CCN4CCN(C3=CC=CC=C3OC)CC4)OC', 'C2=C(OCC1OC(NCC1)=S)C=CC=C2', 'CCC(C)(CC)OC(N)=O']\n",
      "Graph(num_nodes=1514, num_edges=4756,\n",
      "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    \n",
    "    _ = data\n",
    "    \n",
    "    print(len(_))\n",
    "    print(_[0][:3])\n",
    "    print(_[1])\n",
    "    print(_[2][:3])\n",
    "    print(_[3][:3])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40e9c9",
   "metadata": {},
   "source": [
    "## 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "294463fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'batchnorm': False,\n",
       " 'dropout': 0.0272564399565973,\n",
       " 'gnn_hidden_feats': 256,\n",
       " 'lr': 0.02020086171843634,\n",
       " 'num_gnn_layers': 4,\n",
       " 'patience': 30,\n",
       " 'predictor_hidden_feats': 32,\n",
       " 'residual': True,\n",
       " 'weight_decay': 0.001168051063650801,\n",
       " 'in_node_feats': 74,\n",
       " 'n_tasks': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.update({'n_tasks': 1})\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3146df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.model import GCNPredictor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def load_model(config):\n",
    "    model = GCNPredictor(in_feats=config['in_node_feats'],\n",
    "                         hidden_feats=[config['gnn_hidden_feats']] * config['num_gnn_layers'],\n",
    "                         activation=[F.relu] * config['num_gnn_layers'],\n",
    "                         residual=[config['residual']] * config['num_gnn_layers'],\n",
    "                         batchnorm=[config['batchnorm']] * config['num_gnn_layers'],\n",
    "                         dropout=[config['dropout']] * config['num_gnn_layers'],\n",
    "                         predictor_hidden_feats=config['predictor_hidden_feats'],\n",
    "                         predictor_dropout=config['dropout'],\n",
    "                         n_tasks=config['n_tasks']\n",
    "                        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efbe1531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNPredictor(\n",
       "  (gnn): GCN(\n",
       "    (gnn_layers): ModuleList(\n",
       "      (0): GCNLayer(\n",
       "        (graph_conv): GraphConv(in=74, out=256, normalization=none, activation=<function relu at 0x7fa9a131baf0>)\n",
       "        (dropout): Dropout(p=0.0272564399565973, inplace=False)\n",
       "        (res_connection): Linear(in_features=74, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): GCNLayer(\n",
       "        (graph_conv): GraphConv(in=256, out=256, normalization=none, activation=<function relu at 0x7fa9a131baf0>)\n",
       "        (dropout): Dropout(p=0.0272564399565973, inplace=False)\n",
       "        (res_connection): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): GCNLayer(\n",
       "        (graph_conv): GraphConv(in=256, out=256, normalization=none, activation=<function relu at 0x7fa9a131baf0>)\n",
       "        (dropout): Dropout(p=0.0272564399565973, inplace=False)\n",
       "        (res_connection): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): GCNLayer(\n",
       "        (graph_conv): GraphConv(in=256, out=256, normalization=none, activation=<function relu at 0x7fa9a131baf0>)\n",
       "        (dropout): Dropout(p=0.0272564399565973, inplace=False)\n",
       "        (res_connection): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (readout): WeightedSumAndMax(\n",
       "    (weight_and_sum): WeightAndSum(\n",
       "      (atom_weighting): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predict): MLPPredictor(\n",
       "    (predict): Sequential(\n",
       "      (0): Dropout(p=0.0272564399565973, inplace=False)\n",
       "      (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(config).to(args['device'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d034e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For metric roc_auc_score, the higher the better\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "optimizer = Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "stopper = EarlyStopping(patience=config['patience'], filename=args['result_path'] + '/model.pth',\n",
    "                       metric=args['metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66395053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(args, model, bg):\n",
    "    bg = bg.to(args['device'])\n",
    "    if args['edge_featurizer'] is None:\n",
    "        node_feats = bg.ndata.pop('h').to(args['device'])\n",
    "        return model(bg, node_feats)\n",
    "    else:\n",
    "        node_feats = bg.ndata.pop('h').to(args['device'])\n",
    "        edge_feats = bg.edata.pop('h').to(args['device'])\n",
    "        return model(bg, node_feats, edge_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cbe1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "832be9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_a_train_epoch(args, epoch, model, data_loader, loss_criterion, optimizer):\n",
    "    model.train()\n",
    "    train_meter = Meter()\n",
    "    for batch_id, batch_data in enumerate(data_loader):\n",
    "        smiles, bg, labels, masks = batch_data\n",
    "        if len(smiles) == 1:\n",
    "            continue\n",
    "        \n",
    "        labels, masks = labels.to(args['device']), masks.to(args['device'])\n",
    "        logits = predict(args, model, bg)\n",
    "        # mask non-existing labels\n",
    "        loss = (loss_criterion(logits, labels) * (masks != 0).float()).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_meter.update(logits, labels, masks)\n",
    "        \n",
    "        if batch_id % args['print_every'] == 0:\n",
    "            print('epoch {:d}/{:d}, batch {}/{}, loss {:.3f}'.format(\n",
    "                epoch+1, args['num_epochs'], batch_id+1, len(data_loader), loss.item()\n",
    "            ))\n",
    "        \n",
    "    train_score = np.mean(train_meter.compute_metric(args['metric']))\n",
    "    print('epoch {:d}/{:d}, training {} {:.3f}'.format(\n",
    "        epoch+1, args['num_epochs'], args['metric'], train_score)\n",
    "    )\n",
    "        \n",
    "def run_an_eval_epoch(args, model, data_loader):\n",
    "    model.eval()\n",
    "    eval_meter = Meter()\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch_data in enumerate(data_loader):\n",
    "            smiles, bg, labels, masks = batch_data\n",
    "            labels = labels.to(args['device'])\n",
    "            logits = predict(args, model, bg)\n",
    "            eval_meter.update(logits, labels, masks)\n",
    "    return np.mean(eval_meter.compute_metric(args['metric']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15089536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dgllife.utils.eval.Meter at 0x7fa970b10790>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69d9fd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bg = _[1]\n",
    "test_bg.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff743922",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54d13308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1000, batch 1/26, loss 0.718\n",
      "epoch 1/1000, batch 11/26, loss 0.483\n",
      "epoch 1/1000, batch 21/26, loss 0.382\n",
      "epoch 1/1000, training roc_auc_score 0.522\n",
      "epoch 1/1000, validation roc_auc_score 0.727, best validation roc_auc_score 0.727\n",
      "epoch 2/1000, batch 1/26, loss 0.417\n",
      "epoch 2/1000, batch 11/26, loss 0.335\n",
      "epoch 2/1000, batch 21/26, loss 0.543\n",
      "epoch 2/1000, training roc_auc_score 0.668\n",
      "epoch 2/1000, validation roc_auc_score 0.776, best validation roc_auc_score 0.776\n",
      "epoch 3/1000, batch 1/26, loss 0.511\n",
      "epoch 3/1000, batch 11/26, loss 0.466\n",
      "epoch 3/1000, batch 21/26, loss 0.326\n",
      "epoch 3/1000, training roc_auc_score 0.679\n",
      "epoch 3/1000, validation roc_auc_score 0.782, best validation roc_auc_score 0.782\n",
      "epoch 4/1000, batch 1/26, loss 0.421\n",
      "epoch 4/1000, batch 11/26, loss 0.327\n",
      "epoch 4/1000, batch 21/26, loss 0.620\n",
      "epoch 4/1000, training roc_auc_score 0.684\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 4/1000, validation roc_auc_score 0.725, best validation roc_auc_score 0.782\n",
      "epoch 5/1000, batch 1/26, loss 0.453\n",
      "epoch 5/1000, batch 11/26, loss 0.396\n",
      "epoch 5/1000, batch 21/26, loss 0.487\n",
      "epoch 5/1000, training roc_auc_score 0.704\n",
      "epoch 5/1000, validation roc_auc_score 0.812, best validation roc_auc_score 0.812\n",
      "epoch 6/1000, batch 1/26, loss 0.392\n",
      "epoch 6/1000, batch 11/26, loss 0.429\n",
      "epoch 6/1000, batch 21/26, loss 0.332\n",
      "epoch 6/1000, training roc_auc_score 0.709\n",
      "epoch 6/1000, validation roc_auc_score 0.814, best validation roc_auc_score 0.814\n",
      "epoch 7/1000, batch 1/26, loss 0.369\n",
      "epoch 7/1000, batch 11/26, loss 0.482\n",
      "epoch 7/1000, batch 21/26, loss 0.428\n",
      "epoch 7/1000, training roc_auc_score 0.718\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 7/1000, validation roc_auc_score 0.775, best validation roc_auc_score 0.814\n",
      "epoch 8/1000, batch 1/26, loss 0.432\n",
      "epoch 8/1000, batch 11/26, loss 0.316\n",
      "epoch 8/1000, batch 21/26, loss 0.325\n",
      "epoch 8/1000, training roc_auc_score 0.702\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 8/1000, validation roc_auc_score 0.800, best validation roc_auc_score 0.814\n",
      "epoch 9/1000, batch 1/26, loss 0.398\n",
      "epoch 9/1000, batch 11/26, loss 0.370\n",
      "epoch 9/1000, batch 21/26, loss 0.430\n",
      "epoch 9/1000, training roc_auc_score 0.680\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 9/1000, validation roc_auc_score 0.758, best validation roc_auc_score 0.814\n",
      "epoch 10/1000, batch 1/26, loss 0.407\n",
      "epoch 10/1000, batch 11/26, loss 0.390\n",
      "epoch 10/1000, batch 21/26, loss 0.334\n",
      "epoch 10/1000, training roc_auc_score 0.708\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 10/1000, validation roc_auc_score 0.794, best validation roc_auc_score 0.814\n",
      "epoch 11/1000, batch 1/26, loss 0.406\n",
      "epoch 11/1000, batch 11/26, loss 0.496\n",
      "epoch 11/1000, batch 21/26, loss 0.511\n",
      "epoch 11/1000, training roc_auc_score 0.707\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 11/1000, validation roc_auc_score 0.802, best validation roc_auc_score 0.814\n",
      "epoch 12/1000, batch 1/26, loss 0.368\n",
      "epoch 12/1000, batch 11/26, loss 0.324\n",
      "epoch 12/1000, batch 21/26, loss 0.510\n",
      "epoch 12/1000, training roc_auc_score 0.708\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 12/1000, validation roc_auc_score 0.796, best validation roc_auc_score 0.814\n",
      "epoch 13/1000, batch 1/26, loss 0.379\n",
      "epoch 13/1000, batch 11/26, loss 0.485\n",
      "epoch 13/1000, batch 21/26, loss 0.325\n",
      "epoch 13/1000, training roc_auc_score 0.719\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 13/1000, validation roc_auc_score 0.795, best validation roc_auc_score 0.814\n",
      "epoch 14/1000, batch 1/26, loss 0.396\n",
      "epoch 14/1000, batch 11/26, loss 0.412\n",
      "epoch 14/1000, batch 21/26, loss 0.417\n",
      "epoch 14/1000, training roc_auc_score 0.695\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 14/1000, validation roc_auc_score 0.477, best validation roc_auc_score 0.814\n",
      "epoch 15/1000, batch 1/26, loss 0.622\n",
      "epoch 15/1000, batch 11/26, loss 0.422\n",
      "epoch 15/1000, batch 21/26, loss 0.379\n",
      "epoch 15/1000, training roc_auc_score 0.553\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 15/1000, validation roc_auc_score 0.433, best validation roc_auc_score 0.814\n",
      "epoch 16/1000, batch 1/26, loss 0.396\n",
      "epoch 16/1000, batch 11/26, loss 0.558\n",
      "epoch 16/1000, batch 21/26, loss 0.376\n",
      "epoch 16/1000, training roc_auc_score 0.622\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 16/1000, validation roc_auc_score 0.297, best validation roc_auc_score 0.814\n",
      "epoch 17/1000, batch 1/26, loss 0.481\n",
      "epoch 17/1000, batch 11/26, loss 0.433\n",
      "epoch 17/1000, batch 21/26, loss 0.517\n",
      "epoch 17/1000, training roc_auc_score 0.582\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 17/1000, validation roc_auc_score 0.660, best validation roc_auc_score 0.814\n",
      "epoch 18/1000, batch 1/26, loss 0.293\n",
      "epoch 18/1000, batch 11/26, loss 0.265\n",
      "epoch 18/1000, batch 21/26, loss 0.506\n",
      "epoch 18/1000, training roc_auc_score 0.679\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 18/1000, validation roc_auc_score 0.721, best validation roc_auc_score 0.814\n",
      "epoch 19/1000, batch 1/26, loss 0.455\n",
      "epoch 19/1000, batch 11/26, loss 0.523\n",
      "epoch 19/1000, batch 21/26, loss 0.312\n",
      "epoch 19/1000, training roc_auc_score 0.730\n",
      "epoch 19/1000, validation roc_auc_score 0.862, best validation roc_auc_score 0.862\n",
      "epoch 20/1000, batch 1/26, loss 0.590\n",
      "epoch 20/1000, batch 11/26, loss 0.426\n",
      "epoch 20/1000, batch 21/26, loss 0.320\n",
      "epoch 20/1000, training roc_auc_score 0.759\n",
      "epoch 20/1000, validation roc_auc_score 0.907, best validation roc_auc_score 0.907\n",
      "epoch 21/1000, batch 1/26, loss 0.272\n",
      "epoch 21/1000, batch 11/26, loss 0.349\n",
      "epoch 21/1000, batch 21/26, loss 0.252\n",
      "epoch 21/1000, training roc_auc_score 0.793\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 21/1000, validation roc_auc_score 0.902, best validation roc_auc_score 0.907\n",
      "epoch 22/1000, batch 1/26, loss 0.381\n",
      "epoch 22/1000, batch 11/26, loss 0.412\n",
      "epoch 22/1000, batch 21/26, loss 0.303\n",
      "epoch 22/1000, training roc_auc_score 0.794\n",
      "epoch 22/1000, validation roc_auc_score 0.924, best validation roc_auc_score 0.924\n",
      "epoch 23/1000, batch 1/26, loss 0.288\n",
      "epoch 23/1000, batch 11/26, loss 0.427\n",
      "epoch 23/1000, batch 21/26, loss 0.475\n",
      "epoch 23/1000, training roc_auc_score 0.799\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 23/1000, validation roc_auc_score 0.914, best validation roc_auc_score 0.924\n",
      "epoch 24/1000, batch 1/26, loss 0.292\n",
      "epoch 24/1000, batch 11/26, loss 0.373\n",
      "epoch 24/1000, batch 21/26, loss 0.346\n",
      "epoch 24/1000, training roc_auc_score 0.753\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 24/1000, validation roc_auc_score 0.708, best validation roc_auc_score 0.924\n",
      "epoch 25/1000, batch 1/26, loss 0.455\n",
      "epoch 25/1000, batch 11/26, loss 0.292\n",
      "epoch 25/1000, batch 21/26, loss 0.302\n",
      "epoch 25/1000, training roc_auc_score 0.762\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 25/1000, validation roc_auc_score 0.901, best validation roc_auc_score 0.924\n",
      "epoch 26/1000, batch 1/26, loss 0.525\n",
      "epoch 26/1000, batch 11/26, loss 0.277\n",
      "epoch 26/1000, batch 21/26, loss 0.295\n",
      "epoch 26/1000, training roc_auc_score 0.800\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 26/1000, validation roc_auc_score 0.916, best validation roc_auc_score 0.924\n",
      "epoch 27/1000, batch 1/26, loss 0.432\n",
      "epoch 27/1000, batch 11/26, loss 0.422\n",
      "epoch 27/1000, batch 21/26, loss 0.355\n",
      "epoch 27/1000, training roc_auc_score 0.805\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 27/1000, validation roc_auc_score 0.921, best validation roc_auc_score 0.924\n",
      "epoch 28/1000, batch 1/26, loss 0.285\n",
      "epoch 28/1000, batch 11/26, loss 0.269\n",
      "epoch 28/1000, batch 21/26, loss 0.453\n",
      "epoch 28/1000, training roc_auc_score 0.795\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 28/1000, validation roc_auc_score 0.915, best validation roc_auc_score 0.924\n",
      "epoch 29/1000, batch 1/26, loss 0.288\n",
      "epoch 29/1000, batch 11/26, loss 0.315\n",
      "epoch 29/1000, batch 21/26, loss 0.320\n",
      "epoch 29/1000, training roc_auc_score 0.803\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 29/1000, validation roc_auc_score 0.915, best validation roc_auc_score 0.924\n",
      "epoch 30/1000, batch 1/26, loss 0.263\n",
      "epoch 30/1000, batch 11/26, loss 0.182\n",
      "epoch 30/1000, batch 21/26, loss 0.317\n",
      "epoch 30/1000, training roc_auc_score 0.807\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 30/1000, validation roc_auc_score 0.922, best validation roc_auc_score 0.924\n",
      "epoch 31/1000, batch 1/26, loss 0.235\n",
      "epoch 31/1000, batch 11/26, loss 0.484\n",
      "epoch 31/1000, batch 21/26, loss 0.335\n",
      "epoch 31/1000, training roc_auc_score 0.785\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 31/1000, validation roc_auc_score 0.916, best validation roc_auc_score 0.924\n",
      "epoch 32/1000, batch 1/26, loss 0.280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32/1000, batch 11/26, loss 0.294\n",
      "epoch 32/1000, batch 21/26, loss 0.254\n",
      "epoch 32/1000, training roc_auc_score 0.775\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 32/1000, validation roc_auc_score 0.686, best validation roc_auc_score 0.924\n",
      "epoch 33/1000, batch 1/26, loss 0.494\n",
      "epoch 33/1000, batch 11/26, loss 0.465\n",
      "epoch 33/1000, batch 21/26, loss 0.353\n",
      "epoch 33/1000, training roc_auc_score 0.643\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 33/1000, validation roc_auc_score 0.913, best validation roc_auc_score 0.924\n",
      "epoch 34/1000, batch 1/26, loss 0.251\n",
      "epoch 34/1000, batch 11/26, loss 0.280\n",
      "epoch 34/1000, batch 21/26, loss 0.219\n",
      "epoch 34/1000, training roc_auc_score 0.794\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 34/1000, validation roc_auc_score 0.683, best validation roc_auc_score 0.924\n",
      "epoch 35/1000, batch 1/26, loss 0.302\n",
      "epoch 35/1000, batch 11/26, loss 0.409\n",
      "epoch 35/1000, batch 21/26, loss 0.355\n",
      "epoch 35/1000, training roc_auc_score 0.780\n",
      "EarlyStopping counter: 13 out of 30\n",
      "epoch 35/1000, validation roc_auc_score 0.916, best validation roc_auc_score 0.924\n",
      "epoch 36/1000, batch 1/26, loss 0.344\n",
      "epoch 36/1000, batch 11/26, loss 0.356\n",
      "epoch 36/1000, batch 21/26, loss 0.343\n",
      "epoch 36/1000, training roc_auc_score 0.777\n",
      "EarlyStopping counter: 14 out of 30\n",
      "epoch 36/1000, validation roc_auc_score 0.918, best validation roc_auc_score 0.924\n",
      "epoch 37/1000, batch 1/26, loss 0.346\n",
      "epoch 37/1000, batch 11/26, loss 0.291\n",
      "epoch 37/1000, batch 21/26, loss 0.241\n",
      "epoch 37/1000, training roc_auc_score 0.809\n",
      "EarlyStopping counter: 15 out of 30\n",
      "epoch 37/1000, validation roc_auc_score 0.917, best validation roc_auc_score 0.924\n",
      "epoch 38/1000, batch 1/26, loss 0.189\n",
      "epoch 38/1000, batch 11/26, loss 0.414\n",
      "epoch 38/1000, batch 21/26, loss 0.247\n",
      "epoch 38/1000, training roc_auc_score 0.796\n",
      "EarlyStopping counter: 16 out of 30\n",
      "epoch 38/1000, validation roc_auc_score 0.913, best validation roc_auc_score 0.924\n",
      "epoch 39/1000, batch 1/26, loss 0.178\n",
      "epoch 39/1000, batch 11/26, loss 0.351\n",
      "epoch 39/1000, batch 21/26, loss 0.466\n",
      "epoch 39/1000, training roc_auc_score 0.796\n",
      "EarlyStopping counter: 17 out of 30\n",
      "epoch 39/1000, validation roc_auc_score 0.917, best validation roc_auc_score 0.924\n",
      "epoch 40/1000, batch 1/26, loss 0.253\n",
      "epoch 40/1000, batch 11/26, loss 0.369\n",
      "epoch 40/1000, batch 21/26, loss 0.273\n",
      "epoch 40/1000, training roc_auc_score 0.808\n",
      "EarlyStopping counter: 18 out of 30\n",
      "epoch 40/1000, validation roc_auc_score 0.921, best validation roc_auc_score 0.924\n",
      "epoch 41/1000, batch 1/26, loss 0.381\n",
      "epoch 41/1000, batch 11/26, loss 0.444\n",
      "epoch 41/1000, batch 21/26, loss 0.265\n",
      "epoch 41/1000, training roc_auc_score 0.803\n",
      "EarlyStopping counter: 19 out of 30\n",
      "epoch 41/1000, validation roc_auc_score 0.325, best validation roc_auc_score 0.924\n",
      "epoch 42/1000, batch 1/26, loss 0.346\n",
      "epoch 42/1000, batch 11/26, loss 0.373\n",
      "epoch 42/1000, batch 21/26, loss 0.261\n",
      "epoch 42/1000, training roc_auc_score 0.761\n",
      "epoch 42/1000, validation roc_auc_score 0.926, best validation roc_auc_score 0.926\n",
      "epoch 43/1000, batch 1/26, loss 0.434\n",
      "epoch 43/1000, batch 11/26, loss 0.469\n",
      "epoch 43/1000, batch 21/26, loss 0.349\n",
      "epoch 43/1000, training roc_auc_score 0.701\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 43/1000, validation roc_auc_score 0.904, best validation roc_auc_score 0.926\n",
      "epoch 44/1000, batch 1/26, loss 0.301\n",
      "epoch 44/1000, batch 11/26, loss 0.466\n",
      "epoch 44/1000, batch 21/26, loss 0.369\n",
      "epoch 44/1000, training roc_auc_score 0.777\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 44/1000, validation roc_auc_score 0.912, best validation roc_auc_score 0.926\n",
      "epoch 45/1000, batch 1/26, loss 0.523\n",
      "epoch 45/1000, batch 11/26, loss 0.252\n",
      "epoch 45/1000, batch 21/26, loss 0.534\n",
      "epoch 45/1000, training roc_auc_score 0.786\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 45/1000, validation roc_auc_score 0.915, best validation roc_auc_score 0.926\n",
      "epoch 46/1000, batch 1/26, loss 0.223\n",
      "epoch 46/1000, batch 11/26, loss 0.258\n",
      "epoch 46/1000, batch 21/26, loss 0.330\n",
      "epoch 46/1000, training roc_auc_score 0.793\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 46/1000, validation roc_auc_score 0.916, best validation roc_auc_score 0.926\n",
      "epoch 47/1000, batch 1/26, loss 0.305\n",
      "epoch 47/1000, batch 11/26, loss 0.282\n",
      "epoch 47/1000, batch 21/26, loss 0.293\n",
      "epoch 47/1000, training roc_auc_score 0.809\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 47/1000, validation roc_auc_score 0.916, best validation roc_auc_score 0.926\n",
      "epoch 48/1000, batch 1/26, loss 0.414\n",
      "epoch 48/1000, batch 11/26, loss 0.367\n",
      "epoch 48/1000, batch 21/26, loss 0.341\n",
      "epoch 48/1000, training roc_auc_score 0.796\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 48/1000, validation roc_auc_score 0.918, best validation roc_auc_score 0.926\n",
      "epoch 49/1000, batch 1/26, loss 0.267\n",
      "epoch 49/1000, batch 11/26, loss 0.303\n",
      "epoch 49/1000, batch 21/26, loss 0.355\n",
      "epoch 49/1000, training roc_auc_score 0.802\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 49/1000, validation roc_auc_score 0.884, best validation roc_auc_score 0.926\n",
      "epoch 50/1000, batch 1/26, loss 0.374\n",
      "epoch 50/1000, batch 11/26, loss 0.394\n",
      "epoch 50/1000, batch 21/26, loss 0.324\n",
      "epoch 50/1000, training roc_auc_score 0.783\n",
      "epoch 50/1000, validation roc_auc_score 0.938, best validation roc_auc_score 0.938\n",
      "epoch 51/1000, batch 1/26, loss 0.382\n",
      "epoch 51/1000, batch 11/26, loss 0.315\n",
      "epoch 51/1000, batch 21/26, loss 0.336\n",
      "epoch 51/1000, training roc_auc_score 0.820\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 51/1000, validation roc_auc_score 0.451, best validation roc_auc_score 0.938\n",
      "epoch 52/1000, batch 1/26, loss 0.335\n",
      "epoch 52/1000, batch 11/26, loss 0.315\n",
      "epoch 52/1000, batch 21/26, loss 0.316\n",
      "epoch 52/1000, training roc_auc_score 0.821\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 52/1000, validation roc_auc_score 0.933, best validation roc_auc_score 0.938\n",
      "epoch 53/1000, batch 1/26, loss 0.219\n",
      "epoch 53/1000, batch 11/26, loss 0.368\n",
      "epoch 53/1000, batch 21/26, loss 0.315\n",
      "epoch 53/1000, training roc_auc_score 0.830\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 53/1000, validation roc_auc_score 0.932, best validation roc_auc_score 0.938\n",
      "epoch 54/1000, batch 1/26, loss 0.329\n",
      "epoch 54/1000, batch 11/26, loss 0.302\n",
      "epoch 54/1000, batch 21/26, loss 0.286\n",
      "epoch 54/1000, training roc_auc_score 0.807\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 54/1000, validation roc_auc_score 0.935, best validation roc_auc_score 0.938\n",
      "epoch 55/1000, batch 1/26, loss 0.432\n",
      "epoch 55/1000, batch 11/26, loss 0.274\n",
      "epoch 55/1000, batch 21/26, loss 0.260\n",
      "epoch 55/1000, training roc_auc_score 0.832\n",
      "epoch 55/1000, validation roc_auc_score 0.943, best validation roc_auc_score 0.943\n",
      "epoch 56/1000, batch 1/26, loss 0.370\n",
      "epoch 56/1000, batch 11/26, loss 0.268\n",
      "epoch 56/1000, batch 21/26, loss 0.321\n",
      "epoch 56/1000, training roc_auc_score 0.824\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 56/1000, validation roc_auc_score 0.942, best validation roc_auc_score 0.943\n",
      "epoch 57/1000, batch 1/26, loss 0.399\n",
      "epoch 57/1000, batch 11/26, loss 0.395\n",
      "epoch 57/1000, batch 21/26, loss 0.359\n",
      "epoch 57/1000, training roc_auc_score 0.839\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 57/1000, validation roc_auc_score 0.939, best validation roc_auc_score 0.943\n",
      "epoch 58/1000, batch 1/26, loss 0.217\n",
      "epoch 58/1000, batch 11/26, loss 0.165\n",
      "epoch 58/1000, batch 21/26, loss 0.315\n",
      "epoch 58/1000, training roc_auc_score 0.839\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 58/1000, validation roc_auc_score 0.942, best validation roc_auc_score 0.943\n",
      "epoch 59/1000, batch 1/26, loss 0.233\n",
      "epoch 59/1000, batch 11/26, loss 0.426\n",
      "epoch 59/1000, batch 21/26, loss 0.298\n",
      "epoch 59/1000, training roc_auc_score 0.848\n",
      "epoch 59/1000, validation roc_auc_score 0.952, best validation roc_auc_score 0.952\n",
      "epoch 60/1000, batch 1/26, loss 0.265\n",
      "epoch 60/1000, batch 11/26, loss 0.157\n",
      "epoch 60/1000, batch 21/26, loss 0.293\n",
      "epoch 60/1000, training roc_auc_score 0.831\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 60/1000, validation roc_auc_score 0.934, best validation roc_auc_score 0.952\n",
      "epoch 61/1000, batch 1/26, loss 0.667\n",
      "epoch 61/1000, batch 11/26, loss 0.398\n",
      "epoch 61/1000, batch 21/26, loss 0.286\n",
      "epoch 61/1000, training roc_auc_score 0.817\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 61/1000, validation roc_auc_score 0.941, best validation roc_auc_score 0.952\n",
      "epoch 62/1000, batch 1/26, loss 0.254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62/1000, batch 11/26, loss 0.285\n",
      "epoch 62/1000, batch 21/26, loss 0.236\n",
      "epoch 62/1000, training roc_auc_score 0.838\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 62/1000, validation roc_auc_score 0.939, best validation roc_auc_score 0.952\n",
      "epoch 63/1000, batch 1/26, loss 0.408\n",
      "epoch 63/1000, batch 11/26, loss 0.243\n",
      "epoch 63/1000, batch 21/26, loss 0.334\n",
      "epoch 63/1000, training roc_auc_score 0.838\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 63/1000, validation roc_auc_score 0.952, best validation roc_auc_score 0.952\n",
      "epoch 64/1000, batch 1/26, loss 0.206\n",
      "epoch 64/1000, batch 11/26, loss 0.224\n",
      "epoch 64/1000, batch 21/26, loss 0.226\n",
      "epoch 64/1000, training roc_auc_score 0.848\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 64/1000, validation roc_auc_score 0.952, best validation roc_auc_score 0.952\n",
      "epoch 65/1000, batch 1/26, loss 0.217\n",
      "epoch 65/1000, batch 11/26, loss 0.382\n",
      "epoch 65/1000, batch 21/26, loss 0.366\n",
      "epoch 65/1000, training roc_auc_score 0.838\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 65/1000, validation roc_auc_score 0.949, best validation roc_auc_score 0.952\n",
      "epoch 66/1000, batch 1/26, loss 0.238\n",
      "epoch 66/1000, batch 11/26, loss 0.251\n",
      "epoch 66/1000, batch 21/26, loss 0.333\n",
      "epoch 66/1000, training roc_auc_score 0.833\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 66/1000, validation roc_auc_score 0.947, best validation roc_auc_score 0.952\n",
      "epoch 67/1000, batch 1/26, loss 0.404\n",
      "epoch 67/1000, batch 11/26, loss 0.332\n",
      "epoch 67/1000, batch 21/26, loss 0.326\n",
      "epoch 67/1000, training roc_auc_score 0.842\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 67/1000, validation roc_auc_score 0.939, best validation roc_auc_score 0.952\n",
      "epoch 68/1000, batch 1/26, loss 0.424\n",
      "epoch 68/1000, batch 11/26, loss 0.307\n",
      "epoch 68/1000, batch 21/26, loss 0.422\n",
      "epoch 68/1000, training roc_auc_score 0.825\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 68/1000, validation roc_auc_score 0.919, best validation roc_auc_score 0.952\n",
      "epoch 69/1000, batch 1/26, loss 0.294\n",
      "epoch 69/1000, batch 11/26, loss 0.377\n",
      "epoch 69/1000, batch 21/26, loss 0.427\n",
      "epoch 69/1000, training roc_auc_score 0.833\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 69/1000, validation roc_auc_score 0.950, best validation roc_auc_score 0.952\n",
      "epoch 70/1000, batch 1/26, loss 0.299\n",
      "epoch 70/1000, batch 11/26, loss 0.363\n",
      "epoch 70/1000, batch 21/26, loss 0.262\n",
      "epoch 70/1000, training roc_auc_score 0.844\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 70/1000, validation roc_auc_score 0.952, best validation roc_auc_score 0.952\n",
      "epoch 71/1000, batch 1/26, loss 0.261\n",
      "epoch 71/1000, batch 11/26, loss 0.512\n",
      "epoch 71/1000, batch 21/26, loss 0.302\n",
      "epoch 71/1000, training roc_auc_score 0.832\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 71/1000, validation roc_auc_score 0.943, best validation roc_auc_score 0.952\n",
      "epoch 72/1000, batch 1/26, loss 0.259\n",
      "epoch 72/1000, batch 11/26, loss 0.233\n",
      "epoch 72/1000, batch 21/26, loss 0.355\n",
      "epoch 72/1000, training roc_auc_score 0.819\n",
      "EarlyStopping counter: 13 out of 30\n",
      "epoch 72/1000, validation roc_auc_score 0.935, best validation roc_auc_score 0.952\n",
      "epoch 73/1000, batch 1/26, loss 0.239\n",
      "epoch 73/1000, batch 11/26, loss 0.337\n",
      "epoch 73/1000, batch 21/26, loss 0.198\n",
      "epoch 73/1000, training roc_auc_score 0.833\n",
      "EarlyStopping counter: 14 out of 30\n",
      "epoch 73/1000, validation roc_auc_score 0.944, best validation roc_auc_score 0.952\n",
      "epoch 74/1000, batch 1/26, loss 0.295\n",
      "epoch 74/1000, batch 11/26, loss 0.339\n",
      "epoch 74/1000, batch 21/26, loss 0.154\n",
      "epoch 74/1000, training roc_auc_score 0.832\n",
      "EarlyStopping counter: 15 out of 30\n",
      "epoch 74/1000, validation roc_auc_score 0.941, best validation roc_auc_score 0.952\n",
      "epoch 75/1000, batch 1/26, loss 0.321\n",
      "epoch 75/1000, batch 11/26, loss 0.195\n",
      "epoch 75/1000, batch 21/26, loss 0.325\n",
      "epoch 75/1000, training roc_auc_score 0.848\n",
      "EarlyStopping counter: 16 out of 30\n",
      "epoch 75/1000, validation roc_auc_score 0.946, best validation roc_auc_score 0.952\n",
      "epoch 76/1000, batch 1/26, loss 0.183\n",
      "epoch 76/1000, batch 11/26, loss 0.241\n",
      "epoch 76/1000, batch 21/26, loss 0.263\n",
      "epoch 76/1000, training roc_auc_score 0.842\n",
      "EarlyStopping counter: 17 out of 30\n",
      "epoch 76/1000, validation roc_auc_score 0.946, best validation roc_auc_score 0.952\n",
      "epoch 77/1000, batch 1/26, loss 0.374\n",
      "epoch 77/1000, batch 11/26, loss 0.289\n",
      "epoch 77/1000, batch 21/26, loss 0.350\n",
      "epoch 77/1000, training roc_auc_score 0.845\n",
      "epoch 77/1000, validation roc_auc_score 0.958, best validation roc_auc_score 0.958\n",
      "epoch 78/1000, batch 1/26, loss 0.244\n",
      "epoch 78/1000, batch 11/26, loss 0.352\n",
      "epoch 78/1000, batch 21/26, loss 0.195\n",
      "epoch 78/1000, training roc_auc_score 0.842\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 78/1000, validation roc_auc_score 0.950, best validation roc_auc_score 0.958\n",
      "epoch 79/1000, batch 1/26, loss 0.140\n",
      "epoch 79/1000, batch 11/26, loss 0.300\n",
      "epoch 79/1000, batch 21/26, loss 0.412\n",
      "epoch 79/1000, training roc_auc_score 0.820\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 79/1000, validation roc_auc_score 0.947, best validation roc_auc_score 0.958\n",
      "epoch 80/1000, batch 1/26, loss 0.277\n",
      "epoch 80/1000, batch 11/26, loss 0.246\n",
      "epoch 80/1000, batch 21/26, loss 0.232\n",
      "epoch 80/1000, training roc_auc_score 0.794\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 80/1000, validation roc_auc_score 0.944, best validation roc_auc_score 0.958\n",
      "epoch 81/1000, batch 1/26, loss 0.260\n",
      "epoch 81/1000, batch 11/26, loss 0.338\n",
      "epoch 81/1000, batch 21/26, loss 0.334\n",
      "epoch 81/1000, training roc_auc_score 0.799\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 81/1000, validation roc_auc_score 0.948, best validation roc_auc_score 0.958\n",
      "epoch 82/1000, batch 1/26, loss 0.395\n",
      "epoch 82/1000, batch 11/26, loss 0.367\n",
      "epoch 82/1000, batch 21/26, loss 0.255\n",
      "epoch 82/1000, training roc_auc_score 0.793\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 82/1000, validation roc_auc_score 0.938, best validation roc_auc_score 0.958\n",
      "epoch 83/1000, batch 1/26, loss 0.379\n",
      "epoch 83/1000, batch 11/26, loss 0.224\n",
      "epoch 83/1000, batch 21/26, loss 0.337\n",
      "epoch 83/1000, training roc_auc_score 0.831\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 83/1000, validation roc_auc_score 0.927, best validation roc_auc_score 0.958\n",
      "epoch 84/1000, batch 1/26, loss 0.275\n",
      "epoch 84/1000, batch 11/26, loss 0.433\n",
      "epoch 84/1000, batch 21/26, loss 0.395\n",
      "epoch 84/1000, training roc_auc_score 0.709\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 84/1000, validation roc_auc_score 0.935, best validation roc_auc_score 0.958\n",
      "epoch 85/1000, batch 1/26, loss 0.380\n",
      "epoch 85/1000, batch 11/26, loss 0.294\n",
      "epoch 85/1000, batch 21/26, loss 0.475\n",
      "epoch 85/1000, training roc_auc_score 0.809\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 85/1000, validation roc_auc_score 0.941, best validation roc_auc_score 0.958\n",
      "epoch 86/1000, batch 1/26, loss 0.391\n",
      "epoch 86/1000, batch 11/26, loss 0.256\n",
      "epoch 86/1000, batch 21/26, loss 0.280\n",
      "epoch 86/1000, training roc_auc_score 0.841\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 86/1000, validation roc_auc_score 0.943, best validation roc_auc_score 0.958\n",
      "epoch 87/1000, batch 1/26, loss 0.205\n",
      "epoch 87/1000, batch 11/26, loss 0.366\n",
      "epoch 87/1000, batch 21/26, loss 0.241\n",
      "epoch 87/1000, training roc_auc_score 0.845\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 87/1000, validation roc_auc_score 0.938, best validation roc_auc_score 0.958\n",
      "epoch 88/1000, batch 1/26, loss 0.333\n",
      "epoch 88/1000, batch 11/26, loss 0.361\n",
      "epoch 88/1000, batch 21/26, loss 0.214\n",
      "epoch 88/1000, training roc_auc_score 0.848\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 88/1000, validation roc_auc_score 0.958, best validation roc_auc_score 0.958\n",
      "epoch 89/1000, batch 1/26, loss 0.280\n",
      "epoch 89/1000, batch 11/26, loss 0.273\n",
      "epoch 89/1000, batch 21/26, loss 0.239\n",
      "epoch 89/1000, training roc_auc_score 0.830\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 89/1000, validation roc_auc_score 0.923, best validation roc_auc_score 0.958\n",
      "epoch 90/1000, batch 1/26, loss 0.228\n",
      "epoch 90/1000, batch 11/26, loss 0.305\n",
      "epoch 90/1000, batch 21/26, loss 0.369\n",
      "epoch 90/1000, training roc_auc_score 0.824\n",
      "EarlyStopping counter: 13 out of 30\n",
      "epoch 90/1000, validation roc_auc_score 0.940, best validation roc_auc_score 0.958\n",
      "epoch 91/1000, batch 1/26, loss 0.281\n",
      "epoch 91/1000, batch 11/26, loss 0.212\n",
      "epoch 91/1000, batch 21/26, loss 0.313\n",
      "epoch 91/1000, training roc_auc_score 0.842\n",
      "EarlyStopping counter: 14 out of 30\n",
      "epoch 91/1000, validation roc_auc_score 0.927, best validation roc_auc_score 0.958\n",
      "epoch 92/1000, batch 1/26, loss 0.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92/1000, batch 11/26, loss 0.247\n",
      "epoch 92/1000, batch 21/26, loss 0.271\n",
      "epoch 92/1000, training roc_auc_score 0.817\n",
      "EarlyStopping counter: 15 out of 30\n",
      "epoch 92/1000, validation roc_auc_score 0.944, best validation roc_auc_score 0.958\n",
      "epoch 93/1000, batch 1/26, loss 0.264\n",
      "epoch 93/1000, batch 11/26, loss 0.297\n",
      "epoch 93/1000, batch 21/26, loss 0.463\n",
      "epoch 93/1000, training roc_auc_score 0.829\n",
      "EarlyStopping counter: 16 out of 30\n",
      "epoch 93/1000, validation roc_auc_score 0.936, best validation roc_auc_score 0.958\n",
      "epoch 94/1000, batch 1/26, loss 0.271\n",
      "epoch 94/1000, batch 11/26, loss 0.412\n",
      "epoch 94/1000, batch 21/26, loss 0.238\n",
      "epoch 94/1000, training roc_auc_score 0.812\n",
      "EarlyStopping counter: 17 out of 30\n",
      "epoch 94/1000, validation roc_auc_score 0.950, best validation roc_auc_score 0.958\n",
      "epoch 95/1000, batch 1/26, loss 0.199\n",
      "epoch 95/1000, batch 11/26, loss 0.411\n",
      "epoch 95/1000, batch 21/26, loss 0.215\n",
      "epoch 95/1000, training roc_auc_score 0.833\n",
      "EarlyStopping counter: 18 out of 30\n",
      "epoch 95/1000, validation roc_auc_score 0.940, best validation roc_auc_score 0.958\n",
      "epoch 96/1000, batch 1/26, loss 0.327\n",
      "epoch 96/1000, batch 11/26, loss 0.533\n",
      "epoch 96/1000, batch 21/26, loss 0.297\n",
      "epoch 96/1000, training roc_auc_score 0.838\n",
      "EarlyStopping counter: 19 out of 30\n",
      "epoch 96/1000, validation roc_auc_score 0.957, best validation roc_auc_score 0.958\n",
      "epoch 97/1000, batch 1/26, loss 0.338\n",
      "epoch 97/1000, batch 11/26, loss 0.538\n",
      "epoch 97/1000, batch 21/26, loss 0.188\n",
      "epoch 97/1000, training roc_auc_score 0.836\n",
      "EarlyStopping counter: 20 out of 30\n",
      "epoch 97/1000, validation roc_auc_score 0.946, best validation roc_auc_score 0.958\n",
      "epoch 98/1000, batch 1/26, loss 0.410\n",
      "epoch 98/1000, batch 11/26, loss 0.307\n",
      "epoch 98/1000, batch 21/26, loss 0.334\n",
      "epoch 98/1000, training roc_auc_score 0.833\n",
      "EarlyStopping counter: 21 out of 30\n",
      "epoch 98/1000, validation roc_auc_score 0.926, best validation roc_auc_score 0.958\n",
      "epoch 99/1000, batch 1/26, loss 0.348\n",
      "epoch 99/1000, batch 11/26, loss 0.315\n",
      "epoch 99/1000, batch 21/26, loss 0.346\n",
      "epoch 99/1000, training roc_auc_score 0.839\n",
      "EarlyStopping counter: 22 out of 30\n",
      "epoch 99/1000, validation roc_auc_score 0.925, best validation roc_auc_score 0.958\n",
      "epoch 100/1000, batch 1/26, loss 0.379\n",
      "epoch 100/1000, batch 11/26, loss 0.275\n",
      "epoch 100/1000, batch 21/26, loss 0.264\n",
      "epoch 100/1000, training roc_auc_score 0.827\n",
      "EarlyStopping counter: 23 out of 30\n",
      "epoch 100/1000, validation roc_auc_score 0.931, best validation roc_auc_score 0.958\n",
      "epoch 101/1000, batch 1/26, loss 0.421\n",
      "epoch 101/1000, batch 11/26, loss 0.441\n",
      "epoch 101/1000, batch 21/26, loss 0.271\n",
      "epoch 101/1000, training roc_auc_score 0.831\n",
      "EarlyStopping counter: 24 out of 30\n",
      "epoch 101/1000, validation roc_auc_score 0.937, best validation roc_auc_score 0.958\n",
      "epoch 102/1000, batch 1/26, loss 0.361\n",
      "epoch 102/1000, batch 11/26, loss 0.327\n",
      "epoch 102/1000, batch 21/26, loss 0.212\n",
      "epoch 102/1000, training roc_auc_score 0.823\n",
      "EarlyStopping counter: 25 out of 30\n",
      "epoch 102/1000, validation roc_auc_score 0.940, best validation roc_auc_score 0.958\n",
      "epoch 103/1000, batch 1/26, loss 0.278\n",
      "epoch 103/1000, batch 11/26, loss 0.272\n",
      "epoch 103/1000, batch 21/26, loss 0.251\n",
      "epoch 103/1000, training roc_auc_score 0.851\n",
      "EarlyStopping counter: 26 out of 30\n",
      "epoch 103/1000, validation roc_auc_score 0.906, best validation roc_auc_score 0.958\n",
      "epoch 104/1000, batch 1/26, loss 0.269\n",
      "epoch 104/1000, batch 11/26, loss 0.321\n",
      "epoch 104/1000, batch 21/26, loss 0.298\n",
      "epoch 104/1000, training roc_auc_score 0.828\n",
      "EarlyStopping counter: 27 out of 30\n",
      "epoch 104/1000, validation roc_auc_score 0.945, best validation roc_auc_score 0.958\n",
      "epoch 105/1000, batch 1/26, loss 0.277\n",
      "epoch 105/1000, batch 11/26, loss 0.269\n",
      "epoch 105/1000, batch 21/26, loss 0.145\n",
      "epoch 105/1000, training roc_auc_score 0.835\n",
      "EarlyStopping counter: 28 out of 30\n",
      "epoch 105/1000, validation roc_auc_score 0.936, best validation roc_auc_score 0.958\n",
      "epoch 106/1000, batch 1/26, loss 0.269\n",
      "epoch 106/1000, batch 11/26, loss 0.277\n",
      "epoch 106/1000, batch 21/26, loss 0.182\n",
      "epoch 106/1000, training roc_auc_score 0.827\n",
      "EarlyStopping counter: 29 out of 30\n",
      "epoch 106/1000, validation roc_auc_score 0.941, best validation roc_auc_score 0.958\n",
      "epoch 107/1000, batch 1/26, loss 0.267\n",
      "epoch 107/1000, batch 11/26, loss 0.255\n",
      "epoch 107/1000, batch 21/26, loss 0.318\n",
      "epoch 107/1000, training roc_auc_score 0.845\n",
      "EarlyStopping counter: 30 out of 30\n",
      "epoch 107/1000, validation roc_auc_score 0.938, best validation roc_auc_score 0.958\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args['num_epochs']):\n",
    "    # Train\n",
    "    run_a_train_epoch(args, epoch, model, train_loader, loss_criterion, optimizer)\n",
    "    \n",
    "    # Validation and Early stop\n",
    "    val_score = run_an_eval_epoch(args, model, val_loader)\n",
    "    early_stop = stopper.step(val_score, model)\n",
    "    \n",
    "    print('epoch {:d}/{:d}, validation {} {:.3f}, best validation {} {:.3f}'.format(\n",
    "        epoch+1, args['num_epochs'], args['metric'], val_score, args['metric'], stopper.best_score\n",
    "    ))\n",
    "    \n",
    "    if early_stop: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a59bc525",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = run_an_eval_epoch(args, model, val_loader)\n",
    "test_score = run_an_eval_epoch(args, model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cd666e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375684556407449 0.5981385030864197\n"
     ]
    }
   ],
   "source": [
    "print(val_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c0fa7",
   "metadata": {},
   "source": [
    "## 拆解 `run_a_train_epoch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d690928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For metric roc_auc_score, the higher the better\n"
     ]
    }
   ],
   "source": [
    "model = GCNPredictor(in_feats = 74,\n",
    "                     hidden_feats = [256, 128, 64, 32],\n",
    "                     activation = [F.relu] * 4,\n",
    "                     residual = [True] * 4,\n",
    "                     batchnorm = [False] * 4,\n",
    "                     dropout = [0.0, 0.5, 0.25, 0.0],\n",
    "                     predictor_hidden_feats = 32,\n",
    "                     predictor_dropout = 0.25,\n",
    "                     n_tasks = 1\n",
    "                    )\n",
    "\n",
    "model = model.to(args['device'])\n",
    "loss_criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "optimizer = Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "stopper = EarlyStopping(patience=20, filename=args['result_path'] + '/model_custom.pth',\n",
    "                       metric='roc_auc_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53722cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_loader = DataLoader(train_set, batch_size=4, shuffle=True, drop_last=True, collate_fn=collate_molgraphs,\n",
    "                         num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff606b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NC(=N)NCCCOc1ccccc1', 'c1(CC(N2[C@H](CN(CC2)C(=O)C)C[N@]2CC[C@H](O)C2)=O)ccc(N(=O)=O)cc1', 'C1=C(Cl)C=CC3=C1N(C2=CC=CC=C2)C(CCN3)=O', 'CC1CC2C3CC(F)(F)C4=CC(=O)C=C[C@]4(C)C3(F)C(O)CC2(C)C1(O)C(=O)CO']\n",
      "Graph(num_nodes=91, num_edges=287,\n",
      "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "Graph(num_nodes=91, num_edges=287,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "Graph(num_nodes=91, num_edges=287,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "tensor([[-0.1110],\n",
      "        [-0.3321],\n",
      "        [ 0.3468],\n",
      "        [-0.4268]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.7502],\n",
      "        [0.5408],\n",
      "        [0.5347],\n",
      "        [0.9292]], grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor([[True],\n",
      "        [True],\n",
      "        [True],\n",
      "        [True]])\n",
      "tensor(0.6887, grad_fn=<MeanBackward0>)\n",
      "0.6887178421020508\n",
      "[0.6666666666666666]\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_meter = Meter()\n",
    "\n",
    "for batch_id, batch_data in enumerate(demo_loader):\n",
    "    smiles, bg, labels, masks = batch_data\n",
    "    labels, masks = labels.to(args['device']), masks.to(args['device'])\n",
    "    print(smiles)\n",
    "    print(bg)\n",
    "    print(labels)\n",
    "    print(masks)\n",
    "    \n",
    "    # predict function\n",
    "    bg = bg.to(args['device'])\n",
    "    node_feats = bg.ndata.pop('h').to(args['device'])\n",
    "    print(bg)\n",
    "    logits = model(bg, node_feats)\n",
    "    print(bg)\n",
    "    print(logits)\n",
    "    \n",
    "    # mask non-existing labels\n",
    "    print(loss_criterion(logits, labels))\n",
    "    print(masks != 0)\n",
    "    loss = (loss_criterion(logits, labels) * (masks != 0).float()).mean()\n",
    "    print(loss)\n",
    "    print(loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    train_meter.update(logits, labels, masks)\n",
    "    train_score = train_meter.compute_metric('roc_auc_score')\n",
    "    print(train_score)\n",
    "    train_score = np.mean(train_score)\n",
    "    print(train_score)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70085731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch id 50, auc = 0.501\n",
      "batch id 100, auc = 0.543\n",
      "batch id 150, auc = 0.581\n",
      "batch id 200, auc = 0.601\n",
      "batch id 250, auc = 0.611\n",
      "batch id 300, auc = 0.611\n",
      "batch id 350, auc = 0.611\n",
      "batch id 400, auc = 0.614\n",
      "0.6148307310585317\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_meter = Meter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_id, batch_data in enumerate(demo_loader):\n",
    "        smiles, bg, labels, masks = batch_data\n",
    "        labels = labels.to(args['device'])\n",
    "        \n",
    "        bg = bg.to(args['device'])\n",
    "        node_feats = bg.ndata.pop('h').to(args['device'])\n",
    "        logits = model(bg, node_feats)\n",
    "        \n",
    "        eval_meter.update(logits, labels, masks)\n",
    "        if (batch_id+1) % 50 == 0:\n",
    "            print('batch id {}, auc = {:.3f}'.format(batch_id+1, np.mean(eval_meter.compute_metric('roc_auc_score'))))\n",
    "        \n",
    "    print(np.mean(eval_meter.compute_metric('roc_auc_score')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde1b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
